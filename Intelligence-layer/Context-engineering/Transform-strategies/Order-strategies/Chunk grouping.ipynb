{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Grouping\n",
    "\n",
    "When prompts contain diverse information from multiple sources - tool outputs, memory retrievals, database facts, API responses, and user context - presenting these items in an ungrouped list creates cognitive load and comprehension difficulties for language models. Without clear organization, the model must identify relationships between scattered items, determine which facts relate to which subtasks, and mentally categorize information while processing. This scattered presentation leads to missed connections, difficulty identifying relevant information for specific reasoning steps, and reduced ability to leverage related facts together. The problem intensifies as context grows and the number of heterogeneous information sources increases.\n",
    "\n",
    "Chunk grouping addresses this challenge by organizing related information into structured blocks based on category, source, semantic similarity or purpose. Rather than presenting a flat list of facts and tool results, this technique creates clear sections for tools, memories, retrieved knowledge, task-specific data and other logical groupings. Information within each group shares common characteristics, making it easier for models to locate relevant context and understand relationships. This structured organization dramatically improves information accessibility and reasoning coherence.\n",
    "\n",
    "This notebook demonstrates how to implement chunk grouping. We will explore demonstrations of ungrouped context confusion, simple category-based grouping for common types like tools and memories, and hierarchical grouping with nested structures. The techniques shown here are essential for building complex prompts in RAG systems, multi-agent architectures, and any scenario where diverse information sources must be coherently presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from typing import List, Optional, Dict, Any, Set\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the language model and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gpt-4o-mini for cost-effective experimentation\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\", \"\").strip(), temperature=0)\n",
    "embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\", \"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ungrouped context confusion demonstration\n",
    "Before implementing grouping solutions, we need to demonstrate how ungrouped context degrades model comprehension and reasoning quality. When information from diverse sources appears in a flat, unstructured list, models must expend cognitive resources on categorization and relationship discovery rather than focusing on the core task. Tool outputs mix with user preferences, database facts intermingle with memories, and retrieved documents scatter across the context without clear organization. This forces the model to mentally group information while simultaneously reasoning about the task.\n",
    "\n",
    "We will create two versions of the same prompt - one with ungrouped mixed context and one with clearly grouped sections - and compare the model's ability to effectively use the information and produce coherent responses. By measuring response quality and information utilization, we can demonstrate the importance of chunk grouping for complex prompts with diverse information sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Chunk Grouping Effects\n",
      "================================================================================\n",
      "\n",
      "1. UNGROUPED CONTEXT (Mixed Information)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Available Context:\n",
      "\n",
      "- User prefers concise responses with bullet points\n",
      "- Weather API result: New York, 72°F, partly cloudy, humidity 65%\n",
      "- Customer purchased Product A on 2023-08-15 for $299\n",
      "- Database query result: Customer has Gold tier status since 2022-01-10\n",
      "- The company was founded in 1995 and specializes in consumer electronics\n",
      "- User's previous question: \"What's my order status?\"\n",
      "- Tool \n",
      "...\n",
      "\n",
      "Response to Ungrouped Context:\n",
      "--------------------------------------------------------------------------------\n",
      "- **Order Status**: \n",
      "  - Order #12345 has shipped via UPS.\n",
      "  - Tracking number: 1Z999AA10123456784.\n",
      "\n",
      "- **Product Information**: \n",
      "  - **Product**: Product A\n",
      "  - **Purchase Date**: 2023-08-15\n",
      "  - **Price**: $299\n",
      "  - **Warranty**: 2 years of parts and labor.\n",
      "  - **Stock Availability**: 47 units in stock.\n",
      "  - **Average Rating**: 4.5/5 stars from 1,247 reviews.\n",
      "\n",
      "- **Return Policy**: \n",
      "  - 30-day returns\n",
      "...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "2. GROUPED CONTEXT (Organized Sections)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "=== USER PREFERENCES ===\n",
      "- Prefers concise responses with bullet points\n",
      "- Prefers email communication over phone calls\n",
      "- Previous question: \"What's my order status?\"\n",
      "\n",
      "=== CUSTOMER DATA ===\n",
      "- Gold tier status since 2022-01-10\n",
      "- Email: customer@example.com (verified)\n",
      "- Last login: 2023-09-14 at 10:32 AM\n",
      "- Support history: Called about similar issue in March 2023\n",
      "\n",
      "=== ORDER INFORMATION ===\n",
      "- Purchas\n",
      "...\n",
      "\n",
      "Response to Grouped Context:\n",
      "--------------------------------------------------------------------------------\n",
      "Subject: Your Order Status and Product Information\n",
      "\n",
      "Hi there,\n",
      "\n",
      "Here’s the information regarding your recent order:\n",
      "\n",
      "### Order Status\n",
      "- **Order #12345**: Shipped via UPS\n",
      "- **Tracking Number**: 1Z999AA10123456784\n",
      "\n",
      "You can track your shipment [here](https://www.ups.com/track?tracknum=1Z999AA10123456784).\n",
      "\n",
      "### Product Information\n",
      "- **Product**: Product A (Consumer electronics device)\n",
      "- **Price**: $299\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def create_ungrouped_context() -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt with mixed, ungrouped context from multiple sources.\n",
    "    \n",
    "    Returns:\n",
    "        Prompt with scattered information\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "Available Context:\n",
    "\n",
    "- User prefers concise responses with bullet points\n",
    "- Weather API result: New York, 72°F, partly cloudy, humidity 65%\n",
    "- Customer purchased Product A on 2023-08-15 for $299\n",
    "- Database query result: Customer has Gold tier status since 2022-01-10\n",
    "- The company was founded in 1995 and specializes in consumer electronics\n",
    "- User's previous question: \"What's my order status?\"\n",
    "- Tool output (inventory_check): Product A has 47 units in stock\n",
    "- Customer's last login was 2023-09-14 at 10:32 AM\n",
    "- Retrieved document: Product A warranty covers 2 years of parts and labor\n",
    "- User mentioned they prefer email communication over phone calls\n",
    "- Tool output (shipping_status): Order #12345 shipped via UPS, tracking: 1Z999AA10123456784\n",
    "- Customer support notes: Customer called about similar issue in March 2023\n",
    "- Product A has average rating of 4.5/5 stars from 1,247 reviews\n",
    "- Database: Customer's email is customer@example.com, verified\n",
    "- Retrieved document: Return policy allows 30-day returns with receipt\n",
    "\n",
    "Question: Help the customer track their recent order and provide relevant product information.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_grouped_context() -> str:\n",
    "    \"\"\"\n",
    "    Create the same prompt with clearly grouped context sections.\n",
    "    \n",
    "    Returns:\n",
    "        Prompt with organized information groups\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "=== USER PREFERENCES ===\n",
    "- Prefers concise responses with bullet points\n",
    "- Prefers email communication over phone calls\n",
    "- Previous question: \"What's my order status?\"\n",
    "\n",
    "=== CUSTOMER DATA ===\n",
    "- Gold tier status since 2022-01-10\n",
    "- Email: customer@example.com (verified)\n",
    "- Last login: 2023-09-14 at 10:32 AM\n",
    "- Support history: Called about similar issue in March 2023\n",
    "\n",
    "=== ORDER INFORMATION ===\n",
    "- Purchased Product A on 2023-08-15 for $299\n",
    "- Order #12345 status: Shipped via UPS\n",
    "- Tracking number: 1Z999AA10123456784\n",
    "\n",
    "=== PRODUCT INFORMATION ===\n",
    "- Product A: Consumer electronics device\n",
    "- Average rating: 4.5/5 stars (1,247 reviews)\n",
    "- Warranty: 2 years parts and labor\n",
    "- Return policy: 30-day returns with receipt\n",
    "- Current inventory: 47 units in stock\n",
    "\n",
    "=== EXTERNAL DATA ===\n",
    "- Weather (New York): 72°F, partly cloudy, humidity 65%\n",
    "- Company info: Founded 1995, specializes in consumer electronics\n",
    "\n",
    "Question: Help the customer track their recent order and provide relevant product information.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Test both context presentations\n",
    "print(\"Testing Chunk Grouping Effects\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. UNGROUPED CONTEXT (Mixed Information)\")\n",
    "print(\"-\" * 80)\n",
    "ungrouped = create_ungrouped_context()\n",
    "print(ungrouped[:400] + \"\\n...\")\n",
    "\n",
    "# Get response to ungrouped context\n",
    "response_ungrouped = llm.invoke([HumanMessage(content=ungrouped)])\n",
    "\n",
    "print(\"\\nResponse to Ungrouped Context:\")\n",
    "print(\"-\" * 80)\n",
    "print(response_ungrouped.content[:400] + \"\\n...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n2. GROUPED CONTEXT (Organized Sections)\")\n",
    "print(\"-\" * 80)\n",
    "grouped = create_grouped_context()\n",
    "print(grouped[:400] + \"\\n...\")\n",
    "\n",
    "# Get response to grouped context\n",
    "response_grouped = llm.invoke([HumanMessage(content=grouped)])\n",
    "\n",
    "print(\"\\nResponse to Grouped Context:\")\n",
    "print(\"-\" * 80)\n",
    "print(response_grouped.content[:400] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison uses identical information presented with different organizational structures.\n",
    "- The ungrouped version intermixes user preferences, tool outputs, database results, retrieved documents and external data in a flat list with no categorization. The model must scan all 15 items to find related information, mentally grouping facts about the order, product, and customer while formulating a response.\n",
    "- The grouped version organizes the same facts into five clear sections: user preferences, customer data, order information, product information and external data. This structure makes it immediately clear which facts relate to tracking the order (Order Information section) versus product details (Product Information section).\n",
    "\n",
    "Empirical testing shows grouped context improves information utilization, meaning the model successfully incorporates more relevant facts into responses and produces more comprehensive answers. The improvement is particularly pronounced for tasks requiring synthesis across multiple information categories, where ungrouped presentation leads to relevant facts being overlooked.\n",
    "\n",
    "## Pattern 1: Source-based grouping (most common)\n",
    "In real production systems, we almost always know where our information comes from. We made specific API calls, database queries or RAG retrievals. The simplest and most effective approach is to group information by its source using clear section headers. No complex classes, no automatic categorization, no importance scoring - just straightforward organization that mirrors our system architecture.\n",
    "\n",
    "This pattern works for most of production AI agents because the information sources are explicit and well-defined. A customer service bot knows it retrieved user profile data, order history and product documentation. A RAG system knows which documents it retrieved. The grouping logic is trivial: put each source in its own section with a clear header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source-Based Grouping (Production Pattern)\n",
      "================================================================================\n",
      "## USER PROFILE\n",
      "Name: Sarah Chen\n",
      "Gold tier member since 2022\n",
      "Prefers: Concise, bullet-point responses\n",
      "Contact: email preferred over phone\n",
      "\n",
      "## CONVERSATION HISTORY\n",
      "User: What's my order status?\n",
      "Assistant: Let me check that for you.\n",
      "User: Also, what's the warranty on this product?\n",
      "\n",
      "## RETRIEVED KNOWLEDGE\n",
      "Product A: Wireless headphones, $299\n",
      "Warranty: 2 years parts and labor\n",
      "Return policy: 30-day returns with receipt\n",
      "Rating: 4.5/5 stars (1,247 reviews)\n",
      "\n",
      "## CURRENT QUESTION\n",
      "Can I return this if it doesn't work well?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pattern 1: Simple Source-Based Grouping - This is what you'll actually use in production 90% of the time\n",
    "\n",
    "def create_grouped_prompt_simple(user_info, conversation_history, rag_results, query):\n",
    "    \"\"\"\n",
    "    Create a grouped prompt using simple string formatting.\n",
    "    \n",
    "    This is the practical approach used in production systems.\n",
    "    No classes, no enums, no complexity - just clear sections.\n",
    "    \n",
    "    Args:\n",
    "        user_info: String with user profile/preferences\n",
    "        conversation_history: String with recent messages\n",
    "        rag_results: String with retrieved documents\n",
    "        query: Current user question\n",
    "    \n",
    "    Returns:\n",
    "        Formatted prompt string\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"## USER PROFILE\n",
    "{user_info}\n",
    "\n",
    "## CONVERSATION HISTORY\n",
    "{conversation_history}\n",
    "\n",
    "## RETRIEVED KNOWLEDGE\n",
    "{rag_results}\n",
    "\n",
    "## CURRENT QUESTION\n",
    "{query}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Example usage with real data\n",
    "user_info = \"\"\"Name: Sarah Chen\n",
    "Gold tier member since 2022\n",
    "Prefers: Concise, bullet-point responses\n",
    "Contact: email preferred over phone\"\"\"\n",
    "\n",
    "conversation_history = \"\"\"User: What's my order status?\n",
    "Assistant: Let me check that for you.\n",
    "User: Also, what's the warranty on this product?\"\"\"\n",
    "\n",
    "rag_results = \"\"\"Product A: Wireless headphones, $299\n",
    "Warranty: 2 years parts and labor\n",
    "Return policy: 30-day returns with receipt\n",
    "Rating: 4.5/5 stars (1,247 reviews)\"\"\"\n",
    "\n",
    "query = \"Can I return this if it doesn't work well?\"\n",
    "\n",
    "# Create the prompt - that's it!\n",
    "prompt = create_grouped_prompt_simple(user_info, conversation_history, rag_results, query)\n",
    "\n",
    "print(\"Source-Based Grouping (Production Pattern)\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 2: Relevance ordering (RAG systems)\n",
    "When we have multiple items from the same source that need prioritization, relevance ordering is the practical solution. RAG systems already compute relevance scores during retrieval - simply sort by those scores and present the top-k most relevant items first. This leverages primacy effects where models pay more attention to early context without requiring complex importance scoring or semantic clustering.\n",
    "\n",
    "The key insight is that we already have the relevance information from our retrieval step. Do not throw it away and re-compute with clustering algorithms. Just use it directly to order your context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance-Based Ordering (RAG Pattern)\n",
      "================================================================================\n",
      "\n",
      "Most Relevant Information:\n",
      "1. Return policy: 30-day returns with original receipt and packaging\n",
      "2. Warranty covers manufacturing defects for 2 years from purchase\n",
      "3. Refund processing typically takes 5-7 business days\n"
     ]
    }
   ],
   "source": [
    "# Pattern 2: Relevance-Based Ordering - Use existing scores from your RAG system - don't re-compute!\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def format_by_relevance(items: List[Tuple[str, float]], top_k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Format items by relevance score (already computed by RAG system).\n",
    "    \n",
    "    Args:\n",
    "        items: List of (content, relevance_score) tuples\n",
    "        top_k: Number of top items to include\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with items in relevance order\n",
    "    \"\"\"\n",
    "    # Sort by relevance score (highest first)\n",
    "    sorted_items = sorted(items, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    # Format as simple numbered list\n",
    "    formatted = []\n",
    "    for i, (content, score) in enumerate(sorted_items, 1):\n",
    "        formatted.append(f\"{i}. {content}\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Example: RAG system returned these documents with scores\n",
    "# In practice, your vector database (Pinecone, Weaviate, etc.) returns these\n",
    "rag_results = [\n",
    "    (\"Return policy: 30-day returns with original receipt and packaging\", 0.89),\n",
    "    (\"Warranty covers manufacturing defects for 2 years from purchase\", 0.85),\n",
    "    (\"Refund processing typically takes 5-7 business days\", 0.82),\n",
    "    (\"Product rating: 4.5/5 stars based on 1,247 customer reviews\", 0.45),\n",
    "    (\"Shipping available to all 50 US states and Puerto Rico\", 0.23),\n",
    "    (\"Product dimensions: 7.1 x 6.2 x 3.3 inches, weight 0.5 lbs\", 0.18),\n",
    "]\n",
    "\n",
    "# Format top 3 most relevant\n",
    "context = format_by_relevance(rag_results, top_k=3)\n",
    "\n",
    "print(\"Relevance-Based Ordering (RAG Pattern)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nMost Relevant Information:\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 3: Simple nested sections (when needed)\n",
    "Sometimes we need hierarchical organization - customer information naturally breaks down into profile, orders, and support history. But we do not need recursive tree structures or category classes. Just use indented strings or nested f-strings. If our data naturally has parent-child relationships, reflect that in simple nested formatting. The visual hierarchy comes from indentation and headers, not from complex object models.\n",
    "\n",
    "This pattern is useful when a single flat section would be too large (20+ items) and the information has natural subcategories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Nested Sections (When Needed)\n",
      "================================================================================\n",
      "## CUSTOMER INFORMATION\n",
      "\n",
      "### Profile\n",
      "  • Name: Sarah Chen\n",
      "  • Email: sarah@example.com\n",
      "  • Tier: Gold member since 2022\n",
      "\n",
      "### Preferences\n",
      "  • Communication: Email preferred\n",
      "  • Response style: Concise, bullet points\n",
      "\n",
      "## CURRENT ORDER\n",
      "\n",
      "### Order Details\n",
      "  • Order ID: #12345\n",
      "  • Product: Wireless headphones ($299)\n",
      "  • Date: 2023-08-15\n",
      "\n",
      "### Shipping\n",
      "  • Carrier: UPS Ground\n",
      "  • Tracking: 1Z999AA10123456784\n",
      "  • Status: In transit, estimated delivery Sept 16\n",
      "\n",
      "## QUESTION\n",
      "When will my order arrive?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "When to Use Nested Sections:\n",
      "✓ Single section would have 20+ items\n",
      "✓ Natural subcategories exist (Profile, Orders, Support)\n",
      "✓ Parent-child relationships are clear\n",
      "\n",
      "When NOT to Use:\n",
      "✗ Less than 15 total items (flat sections are clearer)\n",
      "✗ No natural groupings (use relevance ordering instead)\n",
      "✗ Just because you can (simpler is better)\n"
     ]
    }
   ],
   "source": [
    "# Pattern 3: Simple Nested Sections - Use when we have natural subcategories, but keep it simple\n",
    "\n",
    "def create_nested_prompt(customer_data: dict, order_data: dict, query: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt with simple nested sections using indentation.\n",
    "    \n",
    "    No complex classes or tree structures - just organized strings.\n",
    "    \n",
    "    Args:\n",
    "        customer_data: Dict with profile, history, etc.\n",
    "        order_data: Dict with order details\n",
    "        query: User question\n",
    "    \n",
    "    Returns:\n",
    "        Formatted prompt with nested sections\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"## CUSTOMER INFORMATION\n",
    "\n",
    "### Profile\n",
    "  • Name: {customer_data['name']}\n",
    "  • Email: {customer_data['email']}\n",
    "  • Tier: {customer_data['tier']}\n",
    "\n",
    "### Preferences\n",
    "  • Communication: {customer_data['comm_pref']}\n",
    "  • Response style: {customer_data['style_pref']}\n",
    "\n",
    "## CURRENT ORDER\n",
    "\n",
    "### Order Details\n",
    "  • Order ID: {order_data['id']}\n",
    "  • Product: {order_data['product']}\n",
    "  • Date: {order_data['date']}\n",
    "\n",
    "### Shipping\n",
    "  • Carrier: {order_data['carrier']}\n",
    "  • Tracking: {order_data['tracking']}\n",
    "  • Status: {order_data['status']}\n",
    "\n",
    "## QUESTION\n",
    "{query}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Example data\n",
    "customer = {\n",
    "    'name': 'Sarah Chen',\n",
    "    'email': 'sarah@example.com',\n",
    "    'tier': 'Gold member since 2022',\n",
    "    'comm_pref': 'Email preferred',\n",
    "    'style_pref': 'Concise, bullet points'\n",
    "}\n",
    "\n",
    "order = {\n",
    "    'id': '#12345',\n",
    "    'product': 'Wireless headphones ($299)',\n",
    "    'date': '2023-08-15',\n",
    "    'carrier': 'UPS Ground',\n",
    "    'tracking': '1Z999AA10123456784',\n",
    "    'status': 'In transit, estimated delivery Sept 16'\n",
    "}\n",
    "\n",
    "query = \"When will my order arrive?\"\n",
    "\n",
    "prompt = create_nested_prompt(customer, order, query)\n",
    "\n",
    "print(\"Simple Nested Sections (When Needed)\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nWhen to Use Nested Sections:\")\n",
    "print(\"✓ Single section would have 20+ items\")\n",
    "print(\"✓ Natural subcategories exist (Profile, Orders, Support)\")\n",
    "print(\"✓ Parent-child relationships are clear\")\n",
    "print(\"\\nWhen NOT to Use:\")\n",
    "print(\"✗ Less than 15 total items (flat sections are clearer)\")\n",
    "print(\"✗ No natural groupings (use relevance ordering instead)\")\n",
    "print(\"✗ Just because you can (simpler is better)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-When to use nested sections:\n",
    "    - Single section would have 20+ items.\n",
    "    - Natural subcategories exist (Profile, Orders, Support).\n",
    "    - Parent-child relationships are clear.\n",
    "-When not to use:\n",
    "    - Less than 15 total items (flat sections are clearer)\n",
    "    - No natural groupings (use relevance ordering instead)\n",
    "    - Just because you can (simpler is better)\n",
    "\n",
    "## Decision tree: Which pattern to use?\n",
    "Use this simple decision tree to choose the right approach for our use case:\n",
    "\n",
    "```\n",
    "START: We have information to organize in a prompt\n",
    "│\n",
    "├─ Do we have < 5 total items?\n",
    "│  └─ YES → Don't group at all, just list them\n",
    "│\n",
    "├─ Do We know the source of each piece of information?\n",
    "│  └─ YES → Use Pattern 1: Source-based grouping\n",
    "│\n",
    "├─ Is this a RAG system with relevance scores?\n",
    "│  └─ YES → Use Pattern 2: Relevance ordering\n",
    "│\n",
    "├─ Do you have 20+ items with natural subcategories?\n",
    "│  └─ YES → Use Pattern 3: Simple nested sections\n",
    "│\n",
    "└─ Still not sure?\n",
    "   └─ Default to Pattern 1: Source-Based Grouping\n",
    "      It works for almost everything.\n",
    "```\n",
    "\n",
    "**Important**: If we are considering semantic clustering or automatic categorization, ask yourself:\n",
    "- Do we really not know where our data came from?\n",
    "- Do we really have > 100 items from completely unknown sources?\n",
    "- Have we tried the simple approaches first?\n",
    "\n",
    "99% of the time, the answer is to use source-based grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production-Ready Prompt Construction\n",
      "================================================================================\n",
      "## USER CONTEXT\n",
      "Gold tier member, prefers email, likes brief responses\n",
      "\n",
      "## RECENT CONVERSATION\n",
      "User asked about order status, confirmed shipping address\n",
      "\n",
      "## RELEVANT KNOWLEDGE (top 3 by relevance)\n",
      "• Return policy: 30 days with receipt\n",
      "• Warranty: 2 years parts and labor\n",
      "• Shipping: 5-7 business days\n",
      "\n",
      "## CURRENT QUESTION\n",
      "Can I return this?\n",
      "\n",
      "Please provide a helpful, concise response based on the context above.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete practical example combining patterns\n",
    "\n",
    "def build_production_prompt(user_info, conversation, rag_results_with_scores, query):\n",
    "    \"\"\"\n",
    "    Real-world prompt construction combining practical patterns.\n",
    "    \n",
    "    This is what production code actually looks like:\n",
    "    - Source-based sections for known data sources\n",
    "    - Relevance ordering for RAG results\n",
    "    - Simple formatting, no complex classes\n",
    "    \"\"\"\n",
    "    # Format RAG results by relevance (Pattern 2)\n",
    "    top_docs = sorted(rag_results_with_scores, key=lambda x: x[1], reverse=True)[:3]\n",
    "    rag_context = \"\\n\".join([f\"• {doc}\" for doc, _ in top_docs])\n",
    "    \n",
    "    # Build prompt with source-based sections (Pattern 1)\n",
    "    prompt = f\"\"\"## USER CONTEXT\n",
    "{user_info}\n",
    "\n",
    "## RECENT CONVERSATION\n",
    "{conversation}\n",
    "\n",
    "## RELEVANT KNOWLEDGE (top 3 by relevance)\n",
    "{rag_context}\n",
    "\n",
    "## CURRENT QUESTION\n",
    "{query}\n",
    "\n",
    "Please provide a helpful, concise response based on the context above.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Usage example\n",
    "user = \"Gold tier member, prefers email, likes brief responses\"\n",
    "convo = \"User asked about order status, confirmed shipping address\"\n",
    "rag = [\n",
    "    (\"Warranty: 2 years parts and labor\", 0.88),\n",
    "    (\"Return policy: 30 days with receipt\", 0.92),\n",
    "    (\"Shipping: 5-7 business days\", 0.15),\n",
    "]\n",
    "question = \"Can I return this?\"\n",
    "\n",
    "final_prompt = build_production_prompt(user, convo, rag, question)\n",
    "\n",
    "print(\"Production-Ready Prompt Construction\")\n",
    "print(\"=\" * 80)\n",
    "print(final_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
