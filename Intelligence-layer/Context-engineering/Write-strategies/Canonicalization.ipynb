{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonicalization\n",
    "\n",
    "In real-world AI agent systems, conversation history and context often accumulate in messy, unstructured formats. Users express the same concepts in different ways, messages contain inconsistent formatting, entities appear with multiple variations, and temporal references use diverse phrasings. This variability makes it difficult for agents to understand and reference past interactions accurately. When an agent needs to retrieve information about \"order #12345\" but the conversation history contains references to \"order 12345\", \"Order #12345\", and \"my order\", the inconsistency hinders effective context utilization.\n",
    "\n",
    "Canonicalization addresses this challenge by transforming unstructured or messy conversation history into normalized, schema-aligned formats that follow consistent patterns. Rather than leaving context in its raw form with all its variations and inconsistencies, we convert it into a standardized representation where entities follow uniform formats, temporal references use consistent structures, and key information is extracted into well-defined fields. This normalization makes context significantly easier for agents to parse, understand, and reference accurately.\n",
    "\n",
    "This notebook demonstrates how to implement canonicalization from basic normalization techniques to production-ready systems. We will explore entity standardization, temporal canonicalization, schema-based conversation normalization, and complete canonicalization pipelines that transform raw conversation history into clean, structured formats optimized for agent comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the language model for canonicalization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gpt-4o-mini for cost-effective text transformation\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\", \"\").strip(), temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic entity normalization\n",
    "The simplest form of canonicalization involves normalizing entities to consistent formats. In conversations, entities like order numbers, phone numbers, email addresses, and product codes often appear in multiple variations. A user might refer to \"order #12345\", \"Order 12345\", or \"my order (12345)\" - all referring to the same entity. These variations create noise in the context and make it harder for the agent to recognize when the same entity is being discussed.\n",
    "\n",
    "We will implement basic entity normalization using regular expressions and string manipulation to convert entities into standard formats. This rule-based approach handles common patterns deterministically, ensuring that all variations of an entity are converted to a single canonical form. While simple, this technique provides immediate benefits for agent comprehension by reducing variability in how key identifiers appear in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Number Normalization:\n",
      "================================================================================\n",
      "  'I need help with my order #12345'\n",
      "  → 'I need help with my ORDER-12345'\n",
      "\n",
      "  'Check Order 67890 status please'\n",
      "  → 'Check ORDER-67890 status please'\n",
      "\n",
      "  'What about order: 11111?'\n",
      "  → 'What about ORDER-11111?'\n",
      "\n",
      "  'Order number 99999 is missing'\n",
      "  → 'ORDER-99999 is missing'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_order_numbers(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize order number references to a consistent format.\n",
    "    Converts variations like \"order #12345\", \"Order 12345\", \"order: 12345\" to the canonical form \"ORDER-12345\".\n",
    "\n",
    "    Args:\n",
    "        text: Input text containing order number references\n",
    "\n",
    "    Returns:\n",
    "        Text with normalized order numbers\n",
    "    \"\"\"\n",
    "    # Define regex pattern to match various order number formats\n",
    "    # \\s* matches zero or more whitespace characters\n",
    "    # (?:number|#|:)? is a non-capturing group that optionally matches \"number\", \"#\", or \":\"\n",
    "    # (\\d{4,6}) captures the order number digits (4 to 6 digits)\n",
    "    pattern = r'order\\s*(?:number|#|:)?\\s*(\\d{4,6})'\n",
    "\n",
    "    # Use re.sub to replace matched patterns with canonical format\n",
    "    # r'ORDER-\\1' references the first captured group (\\d{4,6}) from the pattern\n",
    "    # flags=re.IGNORECASE ensures both \"order\" and \"Order\" are matched\n",
    "    normalized = re.sub(pattern, r'ORDER-\\1', text, flags=re.IGNORECASE)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "# Test order number normalization with various formats\n",
    "test_messages = [\n",
    "    \"I need help with my order #12345\",\n",
    "    \"Check Order 67890 status please\",\n",
    "    \"What about order: 11111?\",\n",
    "    \"Order number 99999 is missing\"\n",
    "]\n",
    "\n",
    "print(\"Order Number Normalization:\")\n",
    "print(\"=\"*80)\n",
    "for msg in test_messages:\n",
    "    normalized = normalize_order_numbers(msg)\n",
    "    print(f\"  '{msg}'\")\n",
    "    print(f\"  → '{normalized}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order number normalization function uses a regular expression pattern with a capturing group to identify order references in multiple formats.\n",
    "- The pattern `order\\s*(?:number|#|:)?\\s*(\\d{4,6})` matches the word \"order\" (case-insensitive due to the IGNORECASE flag), followed by optional whitespace, an optional separator (\"number\", \"#\", or \":\"), more optional whitespace, and finally captures 4-6 digits representing the order ID.\n",
    "- The non-capturing group `(?:...)` is used for the separator to match it without creating a capture group, keeping only the numeric portion as the first captured group.\n",
    "- The replacement string `ORDER-\\1` uses backreference `\\1` to insert the captured digits, producing a uniform \"ORDER-XXXXX\" format. This deterministic transformation ensures that \"order #12345\", \"Order 12345\", and \"order: 12345\" all convert to \"ORDER-12345\", eliminating format variations that would otherwise make it difficult for agents to recognize identical order references.\n",
    "\n",
    "Phone numbers present another common normalization challenge. Users enter phone numbers in diverse formats depending on regional conventions, personal preferences, or input method constraints. The same phone number might appear as \"555-123-4567\", \"(555) 123-4567\", \"555.123.4567\" or even \"5551234567\". This formatting inconsistency creates the same recognition problem as order numbers - the agent cannot easily determine when two differently-formatted phone numbers refer to the same contact. By establishing a single canonical format for all phone numbers in the conversation history, we eliminate this ambiguity and enable reliable phone number matching and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone Number Normalization:\n",
      "================================================================================\n",
      "  'Call me at 555-123-4567'\n",
      "  → 'Call me at (555) 123-4567'\n",
      "\n",
      "  'My number is (555) 987-6543'\n",
      "  → 'My number is (555) 987-6543'\n",
      "\n",
      "  'Reach out to 555.111.2222'\n",
      "  → 'Reach out to (555) 111-2222'\n",
      "\n",
      "  'Contact: 5554445555'\n",
      "  → 'Contact: (555) 444-5555'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_phone_numbers(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize phone number references to a consistent format.\n",
    "    Converts various formats to (XXX) XXX-XXXX.\n",
    "\n",
    "    Args:\n",
    "        text: Input text containing phone numbers\n",
    "\n",
    "    Returns:\n",
    "        Text with normalized phone numbers\n",
    "    \"\"\"\n",
    "    # Define regex pattern to match US phone numbers in various formats\n",
    "    # \\(? matches an optional opening parenthesis\n",
    "    # \\b ensures we're at a word boundary (start of phone number)\n",
    "    # (\\d{3}) captures the three-digit area code as group 1\n",
    "    # \\)? matches an optional closing parenthesis  \n",
    "    # [\\s.-]? matches an optional separator (space, dot, or dash)\n",
    "    # (\\d{3}) captures the three-digit prefix as group 2\n",
    "    # [\\s.-]? matches another optional separator\n",
    "    # (\\d{4}) captures the four-digit line number as group 3\n",
    "    # \\b ensures we're at a word boundary (end of phone number)\n",
    "    pattern = r'\\(?\\b(\\d{3})\\)?[\\s.-]?(\\d{3})[\\s.-]?(\\d{4})\\b'\n",
    "\n",
    "    # Replace with canonical format using captured groups\n",
    "    # \\1, \\2, \\3 reference the three captured groups (area code, prefix, line number)\n",
    "    # Final format: (XXX) XXX-XXXX\n",
    "    normalized = re.sub(pattern, r'(\\1) \\2-\\3', text)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "# Test phone number normalization with various formats\n",
    "test_phone_formats = [\n",
    "    \"Call me at 555-123-4567\",\n",
    "    \"My number is (555) 987-6543\",\n",
    "    \"Reach out to 555.111.2222\",\n",
    "    \"Contact: 5554445555\"\n",
    "]\n",
    "\n",
    "print(\"Phone Number Normalization:\")\n",
    "print(\"=\"*80)\n",
    "for msg in test_phone_formats:\n",
    "    normalized = normalize_phone_numbers(msg)\n",
    "    print(f\"  '{msg}'\")\n",
    "    print(f\"  → '{normalized}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phone number normalization function uses a more complex regex pattern with three separate capturing groups to handle the structure of US phone numbers.\n",
    "- The pattern `\\(?\\b(\\d{3})\\)?[\\s.-]?(\\d{3})[\\s.-]?(\\d{4})\\b` begins with an optional opening parenthesis `\\(?`, followed by a word boundary `\\b` to ensure we match complete phone numbers.\n",
    "    - The first capturing group `(\\d{3})` matches the three-digit area code, followed by an optional closing parenthesis `\\)?` to accommodate formats like \"(555)\" or just \"555\".\n",
    "    - The character class `[\\s.-]?` matches an optional separator which can be a space, dot, or dash.\n",
    "    - The second capturing group `(\\d{3})` captures the three-digit prefix (also called the exchange code), followed by another optional separator.\n",
    "    - Finally, the third capturing group `(\\d{4})` matches the four-digit line number, and `\\b` ensures we're at a word boundary.\n",
    "- The replacement string `(\\1) \\2-\\3` uses backreferences to reconstruct the number in the canonical format: area code in parentheses, space, prefix, dash, and line number. This transformation converts \"555-123-4567\", \"(555) 987-6543\", \"555.111.2222\", and \"5554445555\" all into the uniform \"(555) 123-4567\" style format, eliminating all formatting variations.\n",
    "\n",
    "Email addresses, while typically following a standard format, can still introduce inconsistencies through case variations. The same email address might appear as \"john.doe@example.com\", \"John.Doe@EXAMPLE.COM\", or \"JOHN.DOE@example.com\". According to email standards, the domain portion of email addresses is case-insensitive, and most email providers treat the local part (before the @) as case-insensitive as well. However, when storing email addresses in conversation history, these case variations make it difficult to determine if two references point to the same email. Normalizing all email addresses to lowercase ensures consistent representation and enables reliable matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Address Normalization:\n",
      "================================================================================\n",
      "  'Send confirmation to John.Doe@EXAMPLE.COM'\n",
      "  → 'Send confirmation to john.doe@example.com'\n",
      "\n",
      "  'Contact SUPPORT@Company.NET for help'\n",
      "  → 'Contact support@company.net for help'\n",
      "\n",
      "  'My email is User.Name@Domain.ORG'\n",
      "  → 'My email is user.name@domain.org'\n",
      "\n",
      "  'Reach out at MixedCase@test.Com'\n",
      "  → 'Reach out at mixedcase@test.com'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_email_addresses(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize email addresses to lowercase.\n",
    "    Ensures consistent casing for email references.\n",
    "\n",
    "    Args:\n",
    "        text: Input text containing email addresses\n",
    "\n",
    "    Returns:\n",
    "        Text with normalized email addresses\n",
    "    \"\"\"\n",
    "    # Define regex pattern to match email addresses\n",
    "    # [A-Za-z0-9._%+-]+ matches the local part (before @) - letters, digits, and special chars\n",
    "    # @ matches the literal @ symbol\n",
    "    # [A-Za-z0-9.-]+ matches the domain name - letters, digits, dots, and hyphens\n",
    "    # \\. matches the literal dot before the TLD  \n",
    "    # [A-Z|a-z]{2,} matches the top-level domain (2+ letters)\n",
    "    # \\b ensures word boundaries on both sides\n",
    "    pattern = r'\\b([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,})\\b'\n",
    "\n",
    "    # Define a helper function to convert matched email to lowercase\n",
    "    # This is applied to each match found by re.sub\n",
    "    def lowercase_email(match):\n",
    "        return match.group(0).lower()\n",
    "\n",
    "    # Apply lowercase transformation to all matched email addresses\n",
    "    normalized = re.sub(pattern, lowercase_email, text)\n",
    "\n",
    "    return normalized\n",
    "\n",
    "# Test email normalization with various casing\n",
    "test_email_formats = [\n",
    "    \"Send confirmation to John.Doe@EXAMPLE.COM\",\n",
    "    \"Contact SUPPORT@Company.NET for help\",\n",
    "    \"My email is User.Name@Domain.ORG\",\n",
    "    \"Reach out at MixedCase@test.Com\"\n",
    "]\n",
    "\n",
    "print(\"Email Address Normalization:\")\n",
    "print(\"=\"*80)\n",
    "for msg in test_email_formats:\n",
    "    normalized = normalize_email_addresses(msg)\n",
    "    print(f\"  '{msg}'\")\n",
    "    print(f\"  → '{normalized}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The email normalization function uses a regex pattern that matches the standard email address structure with a callback function for transformation.\n",
    "- The pattern `\\b([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,})\\b` consists of three main parts: the local part `[A-Za-z0-9._%+-]+` before the @ symbol that matches letters, digits, and common email special characters (dots, underscores, percent signs, plus signs, and hyphens); the @ symbol itself; and the domain part `[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}` which matches the domain name followed by a dot and a top-level domain of at least two letters.\n",
    "    - Word boundaries `\\b` ensure we match complete email addresses.\n",
    "- Unlike the previous normalizations that used direct string replacement, this implementation uses a callback function `lowercase_email` that receives each match object and returns the lowercased version.\n",
    "    - The `re.sub` function applies this callback to every matched email address in the text. This approach converts \"John.Doe@EXAMPLE.COM\", \"SUPPORT@Company.NET\", and \"MixedCase@test.Com\" all to their lowercase equivalents, ensuring that \"john.doe@example.com\" is recognized as the same address regardless of how the user originally typed it.\n",
    " \n",
    "Now that we have individual normalization functions for different entity types, we can combine them into a single composite function that applies all normalizations in sequence. This composite approach ensures that every message processed through the canonicalization pipeline receives consistent entity formatting across all entity types. The function chains the individual normalizers, passing the output of one as input to the next, producing text where all entities follow their canonical formats simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite Entity Normalization:\n",
      "================================================================================\n",
      "Original:\n",
      "  Hi, my order #12345 hasn't arrived. Call me at 555-123-4567 or email John.Doe@EXAMPLE.COM\n",
      "Normalized:\n",
      "  Hi, my ORDER-12345 hasn't arrived. Call me at (555) 123-4567 or email john.doe@example.com\n",
      "\n",
      "Original:\n",
      "  Order 67890 needs to be sent to (555) 987-6543, confirmed via SUPPORT@company.net\n",
      "Normalized:\n",
      "  ORDER-67890 needs to be sent to (555) 987-6543, confirmed via support@company.net\n",
      "\n",
      "Original:\n",
      "  Please update order: 11111 and contact me at 555.111.2222 or user@DOMAIN.ORG\n",
      "Normalized:\n",
      "  Please update ORDER-11111 and contact me at (555) 111-2222 or user@domain.org\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize_entities(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply all entity normalization rules to text.\n",
    "    Chains order number, phone number, and email normalization.\n",
    "\n",
    "    Args:\n",
    "        text: Input text with various entity formats\n",
    "\n",
    "    Returns:\n",
    "        Text with all entities normalized\n",
    "    \"\"\"\n",
    "    # Apply each normalization function in sequence\n",
    "    # The output of each function becomes the input to the next\n",
    "    text = normalize_order_numbers(text)\n",
    "    text = normalize_phone_numbers(text)\n",
    "    text = normalize_email_addresses(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Test composite normalization with a message containing multiple entity types\n",
    "test_composite = [\n",
    "    \"Hi, my order #12345 hasn't arrived. Call me at 555-123-4567 or email John.Doe@EXAMPLE.COM\",\n",
    "    \"Order 67890 needs to be sent to (555) 987-6543, confirmed via SUPPORT@company.net\",\n",
    "    \"Please update order: 11111 and contact me at 555.111.2222 or user@DOMAIN.ORG\"\n",
    "]\n",
    "\n",
    "print(\"Composite Entity Normalization:\")\n",
    "print(\"=\"*80)\n",
    "for msg in test_composite:\n",
    "    normalized = normalize_entities(msg)\n",
    "    print(f\"Original:\")\n",
    "    print(f\"  {msg}\")\n",
    "    print(f\"Normalized:\")\n",
    "    print(f\"  {normalized}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The composite `normalize_entities` function creates a processing pipeline by sequentially applying each specialized normalization function.\n",
    "- The text flows through the pipeline: first normalize_order_numbers transforms any order references to \"ORDER-XXXXX\" format, then normalize_phone_numbers standardizes phone numbers to \"(XXX) XXX-XXXX\" format, and finally normalize_email_addresses converts all email addresses to lowercase.\n",
    "- Each function receives the output from the previous function, ensuring that all transformations are applied cumulatively.\n",
    "- The example demonstrates this multi-entity normalization: a message containing \"order #12345\", \"555-123-4567\", and \"John.Doe@EXAMPLE.COM\" gets transformed to \"ORDER-12345\", \"(555) 123-4567\", and \"john.doe@example.com\" in a single pass.\n",
    "- This composable design makes it easy to add additional entity types (like product codes, tracking numbers, or account IDs) by simply adding new normalization functions to the chain. The sequential application ensures consistency and allows downstream components to rely on predictable entity formatting.\n",
    "\n",
    "## Temporal reference canonicalization\n",
    "Conversations frequently contain temporal references that use relative terms like \"yesterday\", \"last week\", \"two days ago\", or \"next Monday\". While humans easily understand these relative references, they become ambiguous in stored conversation history. A message saying \"I ordered it yesterday\" means something different depending on when it was said. When the agent retrieves this message days or weeks later, \"yesterday\" no longer refers to the correct date, causing temporal confusion.\n",
    "\n",
    "Temporal canonicalization converts these relative time references into absolute dates or timestamps. By anchoring temporal expressions to specific dates at the time they are created, we ensure that the meaning remains consistent regardless of when the conversation is retrieved. This is particularly important for long-running agents that maintain conversation history over extended periods, where relative references would otherwise become meaningless or misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Date: March 15, 2024\n",
      "\n",
      "Original Messages (with relative temporal references):\n",
      "================================================================================\n",
      "  I placed my order yesterday and expected it today\n",
      "  The issue started last week when I tried to update my profile\n",
      "  Can you schedule the delivery for tomorrow?\n",
      "  I contacted support 3 days ago but haven't heard back\n",
      "  The payment was processed 7 days ago\n",
      "  Let's schedule a follow-up for next week\n",
      "\n",
      "Canonical Messages (with absolute dates):\n",
      "================================================================================\n",
      "  I placed my order on March 14, 2024 and expected it on March 15, 2024\n",
      "  The issue started around March 08, 2024 when I tried to update my profile\n",
      "  Can you schedule the delivery for on March 16, 2024?\n",
      "  I contacted support on March 12, 2024 but haven't heard back\n",
      "  The payment was processed on March 08, 2024\n",
      "  Let's schedule a follow-up for around March 22, 2024\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Why Canonicalization Matters:\n",
      "If we retrieve 'I placed my order yesterday' on March 25, 2024:\n",
      "  - Without canonicalization: 'yesterday' is ambiguous/wrong\n",
      "  - With canonicalization: 'on March 14, 2024' is precise\n"
     ]
    }
   ],
   "source": [
    "def canonicalize_temporal_references(\n",
    "    text: str, \n",
    "    reference_date: datetime = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert relative temporal references to absolute dates.\n",
    "    Replaces terms like \"yesterday\", \"last week\" with specific dates.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text with relative temporal references\n",
    "        reference_date: The \"current\" date for resolving relative references\n",
    "                       Defaults to now if not provided\n",
    "        \n",
    "    Returns:\n",
    "        Text with absolute date references\n",
    "    \"\"\"\n",
    "    # Use current time as reference if not provided\n",
    "    if reference_date is None:\n",
    "        reference_date = datetime.now()\n",
    "    \n",
    "    # Define temporal patterns and their transformations\n",
    "    # Each pattern maps to a function that calculates the absolute date\n",
    "    \n",
    "    replacements = []\n",
    "    \n",
    "    # \"yesterday\" -> specific date\n",
    "    if \"yesterday\" in text.lower():\n",
    "        yesterday = reference_date - timedelta(days=1)\n",
    "        date_str = yesterday.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((r'\\byesterday\\b', f\"on {date_str}\", re.IGNORECASE))\n",
    "    \n",
    "    # \"today\" -> specific date\n",
    "    if \"today\" in text.lower():\n",
    "        today_str = reference_date.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((r'\\btoday\\b', f\"on {today_str}\", re.IGNORECASE))\n",
    "    \n",
    "    # \"tomorrow\" -> specific date\n",
    "    if \"tomorrow\" in text.lower():\n",
    "        tomorrow = reference_date + timedelta(days=1)\n",
    "        date_str = tomorrow.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((r'\\btomorrow\\b', f\"on {date_str}\", re.IGNORECASE))\n",
    "    \n",
    "    # \"last week\" -> specific date range\n",
    "    if \"last week\" in text.lower():\n",
    "        last_week = reference_date - timedelta(weeks=1)\n",
    "        date_str = last_week.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((r'\\blast week\\b', f\"around {date_str}\", re.IGNORECASE))\n",
    "    \n",
    "    # \"next week\" -> specific date range\n",
    "    if \"next week\" in text.lower():\n",
    "        next_week = reference_date + timedelta(weeks=1)\n",
    "        date_str = next_week.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((r'\\bnext week\\b', f\"around {date_str}\", re.IGNORECASE))\n",
    "    \n",
    "    # \"X days ago\" -> specific date\n",
    "    # Pattern matches \"2 days ago\", \"5 days ago\", etc.\n",
    "    days_ago_pattern = r'(\\d+)\\s+days?\\s+ago'\n",
    "    matches = re.finditer(days_ago_pattern, text, re.IGNORECASE)\n",
    "    for match in matches:\n",
    "        num_days = int(match.group(1))\n",
    "        past_date = reference_date - timedelta(days=num_days)\n",
    "        date_str = past_date.strftime(\"%B %d, %Y\")\n",
    "        replacements.append((match.group(0), f\"on {date_str}\", None))\n",
    "    \n",
    "    # Apply all replacements to the text\n",
    "    result = text\n",
    "    for pattern, replacement, flags in replacements:\n",
    "        if flags:\n",
    "            result = re.sub(pattern, replacement, result, flags=flags)\n",
    "        else:\n",
    "            # For exact string matches from days_ago_pattern\n",
    "            result = result.replace(pattern, replacement)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example: Canonicalize temporal references in conversation\n",
    "# Simulate a conversation from a specific date\n",
    "conversation_date = datetime(2024, 3, 15, 10, 30)\n",
    "\n",
    "temporal_messages = [\n",
    "    \"I placed my order yesterday and expected it today\",\n",
    "    \"The issue started last week when I tried to update my profile\",\n",
    "    \"Can you schedule the delivery for tomorrow?\",\n",
    "    \"I contacted support 3 days ago but haven't heard back\",\n",
    "    \"The payment was processed 7 days ago\",\n",
    "    \"Let's schedule a follow-up for next week\"\n",
    "]\n",
    "\n",
    "print(f\"Conversation Date: {conversation_date.strftime('%B %d, %Y')}\")\n",
    "print(\"\\nOriginal Messages (with relative temporal references):\")\n",
    "print(\"=\"*80)\n",
    "for msg in temporal_messages:\n",
    "    print(f\"  {msg}\")\n",
    "\n",
    "print(\"\\nCanonical Messages (with absolute dates):\")\n",
    "print(\"=\"*80)\n",
    "for msg in temporal_messages:\n",
    "    canonical = canonicalize_temporal_references(msg, conversation_date)\n",
    "    print(f\"  {canonical}\")\n",
    "\n",
    "# Demonstrate why this matters: retrieve the message later\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nWhy Canonicalization Matters:\")\n",
    "print(f\"If we retrieve 'I placed my order yesterday' on {(conversation_date + timedelta(days=10)).strftime('%B %d, %Y')}:\")\n",
    "print(f\"  - Without canonicalization: 'yesterday' is ambiguous/wrong\")\n",
    "print(f\"  - With canonicalization: 'on {(conversation_date - timedelta(days=1)).strftime('%B %d, %Y')}' is precise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal canonicalization uses a reference datetime to resolve relative temporal expressions into absolute dates.\n",
    "- The function maintains a list of replacement patterns, detecting common relative terms like \"yesterday\", \"today\", \"tomorrow\", \"last week\" and \"next week\" in the text. For each detected pattern, it calculates the corresponding absolute date using timedelta operations on the reference date.\n",
    "- The \"X days ago\" pattern uses regex with a capturing group to extract the numeric value, then calculates the past date by subtracting that many days from the reference.\n",
    "- All matched patterns are replaced with formatted absolute dates using strftime.\n",
    "- The example demonstrates how a conversation from March 15, 2024 gets canonicalized: \"yesterday\" becomes \"on March 14, 2024\", \"3 days ago\" becomes \"on March 12, 2024\", and \"next week\" becomes \"around March 22, 2024\".\n",
    "- This transformation ensures that when the conversation is retrieved weeks or months later, the temporal references maintain their original meaning. Without canonicalization, \"yesterday\" would be meaningless or misleading; with canonicalization, the specific date preserves the exact temporal context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema-based conversation canonicalization\n",
    "Beyond normalizing individual entities and temporal references, production systems benefit from transforming entire conversation turns into structured, schema-aligned formats. Raw conversation messages contain unstructured natural language with information scattered throughout. A single message might reference multiple entities, express several intents, and contain both questions and statements. This unstructured format makes it difficult for agents to quickly locate specific information or understand the conversation structure.\n",
    "\n",
    "Schema-based canonicalization uses language models with structured output capabilities to extract information from raw messages and organize it into predefined schemas. Rather than keeping messages as free-form text, we convert them into structured objects with explicit fields for entities, intents, temporal context and other relevant information. This structured representation makes conversation history much easier to parse, search, and reference programmatically, while also ensuring consistency in how information is represented across different message types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonicalizing Conversation Messages\n",
      "================================================================================\n",
      "\n",
      "Original (user at 09:30):\n",
      "  I need help with order #12345 from yesterday\n",
      "\n",
      "Canonical Structure:\n",
      "  Timestamp: 2024-03-15T09:30:00\n",
      "  Speaker: user\n",
      "  Content: I need help with ORDER-12345 from on March 14, 2024\n",
      "  Intent: request\n",
      "  Entities: {'orders': ['ORDER-12345']}\n",
      "  Topics: ['support']\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "Original (assistant at 09:31):\n",
      "  I'd be happy to help with order 12345. Let me look that up.\n",
      "\n",
      "Canonical Structure:\n",
      "  Timestamp: 2024-03-15T09:31:00\n",
      "  Speaker: assistant\n",
      "  Content: I'd be happy to help with ORDER-12345. Let me look that up.\n",
      "  Intent: request\n",
      "  Entities: {'orders': ['ORDER-12345']}\n",
      "  Topics: ['support']\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "Original (user at 09:32):\n",
      "  It was supposed to arrive today but I haven't received it. Please contact me at 555-123-4567\n",
      "\n",
      "Canonical Structure:\n",
      "  Timestamp: 2024-03-15T09:32:00\n",
      "  Speaker: user\n",
      "  Content: It was supposed to arrive on March 15, 2024 but I haven't received it. Please contact me at (555) 123-4567\n",
      "  Intent: complaint\n",
      "  Entities: {'phones': ['555-123-4567']}\n",
      "  Topics: ['delivery', 'support']\n",
      "  ----------------------------------------------------------------------------\n",
      "\n",
      "Original (assistant at 09:35):\n",
      "  I see that ORDER-12345 is delayed. I'll expedite it and call you at (555) 123-4567 tomorrow with an update.\n",
      "\n",
      "Canonical Structure:\n",
      "  Timestamp: 2024-03-15T09:35:00\n",
      "  Speaker: assistant\n",
      "  Content: I see that ORDER-12345 is delayed. I'll expedite it and call you at (555) 123-4567 on March 16, 2024 with an update.\n",
      "  Intent: request\n",
      "  Entities: {'orders': ['ORDER-12345'], 'phones': ['(555) 123-4567'], 'dates': ['March 16, 2024']}\n",
      "  Topics: ['delivery', 'update']\n",
      "  ----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CanonicalMessage(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured schema for canonicalized conversation messages.\n",
    "    Transforms free-form conversation into consistent, parseable format.\n",
    "    \"\"\"\n",
    "    # The original message timestamp for temporal ordering\n",
    "    timestamp: str = Field(\n",
    "        description=\"ISO-format timestamp when message was created\"\n",
    "    )\n",
    "    \n",
    "    # Who sent the message (human/ai/system)\n",
    "    speaker: str = Field(\n",
    "        description=\"Message sender: 'user', 'assistant', or 'system'\"\n",
    "    )\n",
    "    \n",
    "    # Normalized core content\n",
    "    canonical_content: str = Field(\n",
    "        description=\"Message content with entities and temporal refs normalized\"\n",
    "    )\n",
    "    \n",
    "    # Extracted and normalized entities\n",
    "    entities: Dict[str, List[str]] = Field(\n",
    "        description=\"Extracted entities organized by type (orders, emails, phones, etc.)\"\n",
    "    )\n",
    "    \n",
    "    # Primary intent or purpose of the message\n",
    "    intent: str = Field(\n",
    "        description=\"Primary intent: question, request, statement, response, etc.\"\n",
    "    )\n",
    "    \n",
    "    # Topics or themes discussed\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Main topics or subjects discussed in the message\"\n",
    "    )\n",
    "\n",
    "def canonicalize_message(\n",
    "    message: Any,\n",
    "    llm: ChatOpenAI,\n",
    "    message_timestamp: datetime = None\n",
    ") -> CanonicalMessage:\n",
    "    \"\"\"\n",
    "    Transform a raw conversation message into canonical schema format.\n",
    "    Uses LLM to extract structure and normalize content.\n",
    "    \n",
    "    Args:\n",
    "        message: Raw conversation message (HumanMessage, AIMessage, etc.)\n",
    "        llm: Language model for structured extraction\n",
    "        message_timestamp: When the message was created (for temporal canonicalization)\n",
    "        \n",
    "    Returns:\n",
    "        CanonicalMessage with normalized, structured content\n",
    "    \"\"\"\n",
    "    # Default to current time if no timestamp provided\n",
    "    if message_timestamp is None:\n",
    "        message_timestamp = datetime.now()\n",
    "    \n",
    "    # Determine speaker type from message class\n",
    "    if isinstance(message, HumanMessage):\n",
    "        speaker = \"user\"\n",
    "    elif isinstance(message, AIMessage):\n",
    "        speaker = \"assistant\"\n",
    "    elif isinstance(message, SystemMessage):\n",
    "        speaker = \"system\"\n",
    "    else:\n",
    "        speaker = \"unknown\"\n",
    "    \n",
    "    # Apply basic normalization first\n",
    "    normalized_text = normalize_entities(message.content)\n",
    "    normalized_text = canonicalize_temporal_references(\n",
    "        normalized_text, \n",
    "        message_timestamp\n",
    "    )\n",
    "    \n",
    "    # Create prompt for structured extraction\n",
    "    extraction_prompt = f\"\"\"Analyze the following message and extract structured information.\n",
    "\n",
    "Message (already normalized): {normalized_text}\n",
    "Speaker: {speaker}\n",
    "Timestamp: {message_timestamp.isoformat()}\n",
    "\n",
    "Extract:\n",
    "- canonical_content: The normalized message content\n",
    "- entities: Dictionary of entities by type (orders, emails, phones, products, etc.)\n",
    "  Example: {{\"orders\": [\"ORDER-12345\"], \"emails\": [\"user@example.com\"]}}\n",
    "- intent: Primary intent (question, request, complaint, acknowledgment, etc.)\n",
    "- topics: Main topics discussed (delivery, payment, support, etc.)\n",
    "\"\"\"\n",
    "    \n",
    "    # Use structured output to ensure schema compliance\n",
    "    llm_with_structure = llm.with_structured_output(\n",
    "        CanonicalMessage, \n",
    "        method=\"function_calling\" # This is often more resilient to Pydantic defaults\n",
    "    )    \n",
    "    # Generate canonical message structure\n",
    "    canonical = llm_with_structure.invoke([HumanMessage(content=extraction_prompt)])\n",
    "    \n",
    "    return canonical\n",
    "\n",
    "# Example: Canonicalize a sequence of conversation messages\n",
    "raw_messages = [\n",
    "    (HumanMessage(content=\"I need help with order #12345 from yesterday\"), \n",
    "     datetime(2024, 3, 15, 9, 30)),\n",
    "    \n",
    "    (AIMessage(content=\"I'd be happy to help with order 12345. Let me look that up.\"),\n",
    "     datetime(2024, 3, 15, 9, 31)),\n",
    "    \n",
    "    (HumanMessage(content=\"It was supposed to arrive today but I haven't received it. Please contact me at 555-123-4567\"),\n",
    "     datetime(2024, 3, 15, 9, 32)),\n",
    "    \n",
    "    (AIMessage(content=\"I see that ORDER-12345 is delayed. I'll expedite it and call you at (555) 123-4567 tomorrow with an update.\"),\n",
    "     datetime(2024, 3, 15, 9, 35)),\n",
    "]\n",
    "\n",
    "print(\"Canonicalizing Conversation Messages\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "canonical_conversation = []\n",
    "\n",
    "for message, timestamp in raw_messages:\n",
    "    canonical = canonicalize_message(message, llm, timestamp)\n",
    "    canonical_conversation.append(canonical)\n",
    "    \n",
    "    print(f\"\\nOriginal ({canonical.speaker} at {timestamp.strftime('%H:%M')}):\")\n",
    "    print(f\"  {message.content}\")\n",
    "    \n",
    "    print(f\"\\nCanonical Structure:\")\n",
    "    print(f\"  Timestamp: {canonical.timestamp}\")\n",
    "    print(f\"  Speaker: {canonical.speaker}\")\n",
    "    print(f\"  Content: {canonical.canonical_content}\")\n",
    "    print(f\"  Intent: {canonical.intent}\")\n",
    "    print(f\"  Entities: {canonical.entities}\")\n",
    "    print(f\"  Topics: {canonical.topics}\")\n",
    "    print(\"  \" + \"-\"*76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema-based canonicalization combines rule-based normalization with LLM-powered structured extraction.\n",
    "- The `CanonicalMessage` Pydantic model defines six fields that capture different aspects of a message: timestamp for temporal ordering, speaker identification, normalized content, extracted entities organized by type, primary intent and relevant topics.\n",
    "- The `canonicalize_message` function first applies entity and temporal normalization to the raw message content, then constructs a prompt instructing the LLM to extract structured information from the normalized text.\n",
    "- Using LangChain's `with_structured_output` method enforces that the LLM's response conforms to the `CanonicalMessage` schema. The resulting structure provides a machine-readable representation of the conversation turn.\n",
    "- In the example, we see how a raw message \"I need help with order #12345 from yesterday\" gets transformed into a canonical structure with normalized content (\"I need help with ORDER-12345 from on March 14, 2024\"), extracted entities ({\"orders\": [\"ORDER-12345\"]}), identified intent (\"request\"), and relevant topics ([\"order support\", \"delivery\"]). This structured format makes it trivial to programmatically answer questions like \"Which orders were discussed?\", \"What was the user's intent?\", or \"When was this message sent?\", significantly improving the agent's ability to reference and utilize conversation history."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
