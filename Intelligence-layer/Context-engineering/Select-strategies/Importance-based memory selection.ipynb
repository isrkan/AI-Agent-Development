{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance-based memory selection\n",
    "\n",
    "AI agents with memory capabilities accumulate vast amounts of interaction history over time - past conversations, user preferences, task outcomes, feedback signals and contextual observations. While this rich memory enables personalization and continuity, it creates a fundamental challenge: context windows are finite, and not all memories are equally valuable. Loading every stored memory into each request wastes tokens on trivial details while potentially crowding out critical information that should influence the agent's behavior.\n",
    "\n",
    "Importance-based memory selection addresses this challenge by assigning significance scores to memories and using these scores to prioritize what gets loaded into context. Rather than treating all memories equally or simply using recency as a proxy for relevance, we explicitly model importance through signals like user feedback, task success rates, business impact, and contextual relevance. This allows agents to maintain extensive memory stores while selectively surfacing only the most impactful information for each interaction.\n",
    "\n",
    "In this notebook, we explore how to implement importance-based memory selection as a sophisticated select strategy for context engineering. We will examine different dimensions of memory importance including user feedback signals, task outcome tracking, business impact scoring and contextual relevance, how to combine multiple importance signals into composite scores, how to select memory subsets under token budget constraints, and how to build production-ready memory ranking systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by initializing the language model that will use our selected memories to generate personalized responses. Consistent model configuration ensures reproducible behavior across different memory selection strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model for generating responses\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\", \"\").strip(),\n",
    "    temperature=0  # Set to 0 for more deterministic outputs\n",
    ")\n",
    "\n",
    "# Initialize embedding model for semantic similarity\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=os.getenv(\"OPENAI_API_KEY\", \"\").strip())\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Modeling memory with importance scores\n",
    "The foundation of importance-based memory selection lies in how we model memories themselves. Unlike simple memory systems that store just content and timestamps, an importance-based system needs to capture a rich tapestry of signals that indicate value. Think about how we remember things in our own life - we do not just remember facts, we remember how we felt about them, whether they proved useful, and how often we have needed them. Our memory system should work similarly.\n",
    "\n",
    "When an AI agent interacts with users over time, different memories accumulate different kinds of value. A user preference that led to a successful purchase is more valuable than a casual question from months ago. A fact that the user explicitly saved deserves more weight than something mentioned in passing. A memory that gets referenced frequently in conversations signals ongoing relevance. To capture these nuances, we need to track multiple dimensions: user feedback signals that indicate explicit or implicit approval, task outcome tracking that shows whether information led to successful completions, business value metrics that tie memories to real-world impact like revenue or strategic goals, temporal factors that account for both recency and decay over time, and usage patterns that reveal which memories prove consistently useful.\n",
    "\n",
    "The challenge is combining these disparate signals into a single, actionable importance score. We can not simply add them up - a very old but highly successful memory might be less relevant than a recent moderate-success memory depending on the context. We need a flexible scoring system that can weight different factors appropriately for different use cases, while providing clear explanations for why certain memories rank higher than others. Let's build this step by step, starting with defining the structure of our memories and the types they can represent.\n",
    "\n",
    "First, we need to categorize the different kinds of information an agent might remember. Not all memories serve the same purpose - some capture user preferences like product choices or communication styles, others record task outcomes showing what worked or failed, some preserve conversation history for context continuity, and still others store factual information or explicit feedback. By classifying memories into types, we can apply type-specific importance weighting and selection strategies later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryType(Enum):\n",
    "    \"\"\"Types of memories an agent might store.\"\"\"\n",
    "    USER_PREFERENCE = \"user_preference\"  # Preferences and choices the user has expressed\n",
    "    TASK_OUTCOME = \"task_outcome\"  # Results from completed tasks or actions\n",
    "    CONVERSATION = \"conversation\"  # Past conversation exchanges\n",
    "    FACTUAL_INFO = \"factual_info\"  # Facts learned about user or their context\n",
    "    FEEDBACK = \"feedback\"  # Explicit user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With memory types defined, we can now build the complete `Memory` data structure that captures all the dimensions of importance we discussed. This is where the real power of importance-based selection comes from - rather than just storing content and a timestamp, we track a comprehensive set of signals that collectively indicate value. The `Memory` class needs to hold the actual content and its type, temporal information like creation time and access patterns, user feedback signals that might be explicit like a save button or implicit like ratings, task success indicators showing whether this information led to successful outcomes when used previously, business metrics that tie memories to organizational goals or revenue, and metadata like tags for additional categorization.\n",
    "\n",
    "Beyond just storing these fields, the `Memory` class provides a crucial method that synthesizes all these signals into a single importance score. This `calculate_importance_score` method implements a weighted combination approach where different dimensions contribute proportionally to the final score. The weights are configurable because different applications have different priorities - a customer support agent might weight user feedback heavily, while a sales agent might prioritize business value and revenue impact. The method returns a normalized score between 0 and 1, making it easy to compare memories and apply thresholds. Let's implement this comprehensive memory model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Memory:\n",
    "    \"\"\"Memory with comprehensive importance tracking.\"\"\"\n",
    "    \n",
    "    # Core content\n",
    "    content: str  # The actual information being stored\n",
    "    memory_type: MemoryType  # What category this memory falls into (preference, conversation, etc.)\n",
    "    \n",
    "    # Temporal information\n",
    "    created_at: datetime  # When this memory was first created\n",
    "    last_accessed: Optional[datetime] = None  # Last time this memory was retrieved and used (None if never accessed)\n",
    "    access_count: int = 0  # How many times this memory has been selected and used\n",
    "    \n",
    "    # User feedback signals\n",
    "    user_feedback_score: float = 0.0  # -1 (negative) to 1 (positive)\n",
    "    user_explicitly_saved: bool = False  # Whether user explicitly clicked \"save this\" or similar action\n",
    "    \n",
    "    # Task success signals\n",
    "    led_to_task_success: Optional[bool] = None  # Did this memory lead to successful task completion when last used?\n",
    "    task_success_rate: float = 0.0  # For memories used multiple times, what is the success rate?\n",
    "    \n",
    "    # Business impact\n",
    "    business_value: float = 0.0  # 0-1 score for business importance\n",
    "    revenue_impact: float = 0.0  # Estimated revenue impact\n",
    "    \n",
    "    # Metadata - Tags for categorization and filtering\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def calculate_importance_score(self, \n",
    "                                   current_context: Optional[str] = None,\n",
    "                                   weights: Optional[Dict[str, float]] = None) -> float:\n",
    "        \"\"\"Calculate composite importance score from multiple signals. Combines user feedback, task success, business value, recency, and access frequency into a single 0-1 score representing memory importance.\n",
    "        \n",
    "        Args:\n",
    "            current_context: Current user query for contextual relevance\n",
    "            weights: Weight factors for different importance dimensions\n",
    "            \n",
    "        Returns:\n",
    "            Importance score (0-1)\n",
    "        \"\"\"\n",
    "        # Default weights if not provided - These weights determine how much each dimension contributes to final score\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'feedback': 0.3,\n",
    "                'task_success': 0.25,\n",
    "                'business_value': 0.2,\n",
    "                'recency': 0.15,\n",
    "                'access_frequency': 0.1\n",
    "            }\n",
    "        \n",
    "        # Component 1: User feedback signal (normalized to 0-1)\n",
    "        feedback_component = (self.user_feedback_score + 1) / 2  # Convert feedback score from [-1, 1] range to [0, 1] range\n",
    "        # Boost score if user explicitly saved this memory (shows strong intent)\n",
    "        if self.user_explicitly_saved:\n",
    "            feedback_component = min(1.0, feedback_component + 0.3)\n",
    "        \n",
    "        # Component 2: Task success signal\n",
    "        task_component = 0.5  # Start with neutral score if we don't know success/failure\n",
    "        # If we have explicit success/failure data, use it\n",
    "        if self.led_to_task_success is not None:\n",
    "            # Success = 1.0, failure = 0.2 (we still learn from failures)\n",
    "            task_component = 1.0 if self.led_to_task_success else 0.2\n",
    "        # If we have success rate from multiple uses, prefer that (more reliable)\n",
    "        if self.task_success_rate > 0:\n",
    "            task_component = self.task_success_rate\n",
    "        \n",
    "        # Component 3: Business value\n",
    "        business_component = self.business_value  # Direct business value score\n",
    "        \n",
    "        # Component 4: Recency (decay over time)\n",
    "        age_days = (datetime.now() - self.created_at).days  # Calculate how old this memory is in days\n",
    "        recency_component = max(0, 1 - (age_days / 365))  # Apply linear decay over one year (recent = 1.0, year+ old = 0.0)\n",
    "        \n",
    "        # Component 5: Access frequency (normalized by log to prevent dominance)\n",
    "        import math\n",
    "        frequency_component = min(1.0, math.log(self.access_count + 1) / 5)\n",
    "        \n",
    "        # Combine weighted components\n",
    "        importance = (\n",
    "            weights['feedback'] * feedback_component +\n",
    "            weights['task_success'] * task_component +\n",
    "            weights['business_value'] * business_component +\n",
    "            weights['recency'] * recency_component +\n",
    "            weights['access_frequency'] * frequency_component\n",
    "        )\n",
    "\n",
    "        # Ensure final score stays in valid [0, 1] range\n",
    "        return min(1.0, max(0.0, importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `Memory` class defined, we need to create a diverse set of sample memories that demonstrate different importance profiles. This is crucial for testing our selection strategies - we want memories that vary across all the dimensions we track. Some memories should have high user feedback but low business value, others should be recent but have neutral feedback, and still others should be old but frequently accessed. By creating this variety, we can observe how our importance scoring algorithm differentiates between memories and ensures the right ones surface in different contexts.\n",
    "\n",
    "Our sample memories will represent a realistic scenario of an e-commerce agent helping a user shop for electronics. We will include a high-value user preference that was explicitly saved and has led to successful outcomes, an old conversation fragment that has not proven particularly useful, a budget preference that is business-critical and frequently referenced, a recent successful recommendation that drove revenue, contextual information about the user's lifestyle that's moderately useful, and a failed recommendation that teaches us what not to do. This mix will let us see importance-based selection in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 sample memories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Capture current time for calculating relative dates\n",
    "now = datetime.now()\n",
    "\n",
    "# Create a diverse set of memories with varying importance signals\n",
    "sample_memories = [\n",
    "    # Memory 1: High-value user preference. Explicitly saved, positive feedback, high success rate. Should score very high on importance\n",
    "    Memory(\n",
    "        content=\"User prefers eco-friendly packaging and sustainable products\",\n",
    "        memory_type=MemoryType.USER_PREFERENCE,\n",
    "        created_at=now - timedelta(days=30),  # One month old\n",
    "        access_count=5,  # Accessed multiple times\n",
    "        user_feedback_score=1.0,  # Maximum positive feedback\n",
    "        user_explicitly_saved=True,  # User clicked \"remember this\"\n",
    "        led_to_task_success=True,  # Led to successful purchases\n",
    "        task_success_rate=0.9,  # 90% success rate when used\n",
    "        business_value=0.8,  # High strategic value (brand alignment)\n",
    "        tags=[\"preference\", \"sustainability\"]\n",
    "    ),\n",
    "    # Memory 2: Old, low-value conversation. Old, rarely accessed, no clear value signals. Should score low on importance\n",
    "    Memory(\n",
    "        content=\"User asked about laptop specifications on 2024-01-15\",\n",
    "        memory_type=MemoryType.CONVERSATION,\n",
    "        created_at=now - timedelta(days=200),  # Over 6 months old\n",
    "        access_count=1,  # Only accessed once (when created)\n",
    "        user_feedback_score=0.0,  # No feedback\n",
    "        business_value=0.2,  # Low business value\n",
    "        tags=[\"conversation\", \"product_inquiry\"]\n",
    "    ),\n",
    "    # Memory 3: Critical budget preference. Business-critical, frequently used, high success. Should score very high (highest importance)\n",
    "    Memory(\n",
    "        content=\"User's budget range is $800-$1200 for electronics\",\n",
    "        memory_type=MemoryType.USER_PREFERENCE,\n",
    "        created_at=now - timedelta(days=60),  # Two months old\n",
    "        access_count=8,  # Heavily accessed\n",
    "        user_feedback_score=0.5,  # Moderate positive feedback\n",
    "        led_to_task_success=True,  # Leads to purchases\n",
    "        task_success_rate=0.85,  # 85% success rate\n",
    "        business_value=0.9,  # Critical for conversions\n",
    "        revenue_impact=1000.0,  # Estimated $1000 revenue driven\n",
    "        tags=[\"preference\", \"budget\"]\n",
    "    ),\n",
    "    # Memory 4: Recent successful recommendation. Very recent, drove revenue, positive outcome. Should score high (recency + success)\n",
    "    Memory(\n",
    "        content=\"Recommended cooling pad, user purchased it and left positive review\",\n",
    "        memory_type=MemoryType.TASK_OUTCOME,\n",
    "        created_at=now - timedelta(days=10),  # Very recent (10 days)\n",
    "        access_count=2,  # Accessed a couple times\n",
    "        user_feedback_score=1.0,  # Positive review\n",
    "        led_to_task_success=True,  # Purchase completed\n",
    "        business_value=0.7,  # Good business value (conversion)\n",
    "        revenue_impact=49.99,  # $49.99 revenue\n",
    "        tags=[\"recommendation\", \"success\"]\n",
    "    ),\n",
    "    # Memory 5: Contextual information (moderate value). Useful context but not critical. Should score medium importance\n",
    "    Memory(\n",
    "        content=\"User mentioned they work from home\",\n",
    "        memory_type=MemoryType.FACTUAL_INFO,\n",
    "        created_at=now - timedelta(days=45),  # Month and a half old\n",
    "        access_count=3,  # Occasionally referenced\n",
    "        user_feedback_score=0.0,  # No explicit feedback\n",
    "        business_value=0.4,  # Moderate value (helps personalization)\n",
    "        tags=[\"context\", \"lifestyle\"]\n",
    "    ),\n",
    "    # Memory 6: Failed recommendation. Negative feedback, didn't lead to success. Should score low (but not zero - we learn from failures)\n",
    "    Memory(\n",
    "        content=\"Previous recommendation for expensive laptop was rejected\",\n",
    "        memory_type=MemoryType.TASK_OUTCOME,\n",
    "        created_at=now - timedelta(days=70),  # Over two months old\n",
    "        access_count=1,  # Not frequently referenced\n",
    "        user_feedback_score=-0.5,  # Negative feedback\n",
    "        led_to_task_success=False,  # User rejected recommendation\n",
    "        business_value=0.3,  # Some value (teaches us what not to do)\n",
    "        tags=[\"recommendation\", \"failure\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(sample_memories)} sample memories\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our diverse set of sample memories created, let's now calculate and display their importance scores to see how our multi-dimensional scoring algorithm differentiates between them. This is the moment where all those tracked signals - feedback, task success, business value, recency and access frequency - come together into actionable rankings. We should see the budget preference and sustainability preference scoring highest because they combine multiple strong signals, the recent successful recommendation scoring high due to recency and positive outcomes, the contextual information and old conversation scoring lower due to weaker signals, and the failed recommendation scoring lowest despite having some learning value.\n",
    "\n",
    "By displaying not just the scores but also the underlying signals that contributed to each score, we can understand and validate how the importance calculation works. This transparency is crucial for production systems where we need to explain why certain memories were selected or debug unexpected selection behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory importance scores:\n",
      "======================================================================\n",
      "\n",
      "1. [Importance: 0.859]\n",
      "   User prefers eco-friendly packaging and sustainable products\n",
      "   Type: user_preference | Age: 30 days\n",
      "   Feedback: +1.0 | Task success: True\n",
      "\n",
      "2. [Importance: 0.397]\n",
      "   User asked about laptop specifications on 2024-01-15\n",
      "   Type: conversation | Age: 200 days\n",
      "   Feedback: +0.0 | Task success: None\n",
      "\n",
      "3. [Importance: 0.787]\n",
      "   User's budget range is $800-$1200 for electronics\n",
      "   Type: user_preference | Age: 60 days\n",
      "   Feedback: +0.5 | Task success: True\n",
      "\n",
      "4. [Importance: 0.858]\n",
      "   Recommended cooling pad, user purchased it and left positive review\n",
      "   Type: task_outcome | Age: 10 days\n",
      "   Feedback: +1.0 | Task success: True\n",
      "\n",
      "5. [Importance: 0.514]\n",
      "   User mentioned they work from home\n",
      "   Type: factual_info | Age: 45 days\n",
      "   Feedback: +0.0 | Task success: None\n",
      "\n",
      "6. [Importance: 0.320]\n",
      "   Previous recommendation for expensive laptop was rejected\n",
      "   Type: task_outcome | Age: 70 days\n",
      "   Feedback: -0.5 | Task success: False\n"
     ]
    }
   ],
   "source": [
    "# Display importance scores for all memories\n",
    "print(\"Memory importance scores:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Iterate through each memory and show its importance calculation\n",
    "for i, mem in enumerate(sample_memories, 1):\n",
    "    # Calculate the composite importance score for this memory\n",
    "    score = mem.calculate_importance_score()\n",
    "    print(f\"\\n{i}. [Importance: {score:.3f}]\")  # Display memory number and importance score\n",
    "    print(f\"   {mem.content}\")  # Show the actual memory content\n",
    "    print(f\"   Type: {mem.memory_type.value} | Age: {(now - mem.created_at).days} days\")  # Display key metadata that influenced the score\n",
    "    print(f\"   Feedback: {mem.user_feedback_score:+.1f} | Task success: {mem.led_to_task_success}\")  # Show feedback and success signals (these are major contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Memory` class uses Python dataclasses for clean field definitions with default values and provides a comprehensive importance modeling framework:\n",
    "1. Defines a rich memory structure capturing content, type, temporal information, feedback signals, success tracking, and business metrics.\n",
    "2. Implements a composite importance calculation combining multiple signals with configurable weights for different domains.\n",
    "3. Creates diverse sample memories demonstrating varying importance profiles from highly valuable preferences to low-value conversation snippets.\n",
    "4. Calculates importance scores showing clear differentiation between critical information (user preferences with high feedback) and trivial details (old conversation fragments).\n",
    "\n",
    "This foundation enables intelligent memory selection based on true value rather than arbitrary heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Importance-based ranking and selection\n",
    "\n",
    "With importance scores calculated, we can now implement selection strategies that determine which memories get loaded into the agent's context. The simplest approach is top-k selection, where we rank all memories by importance and take the k highest-scoring items. This ensures the most valuable information is always included, though it may miss contextually relevant but lower-scoring memories.\n",
    "\n",
    "More sophisticated strategies might combine importance with other factors like semantic relevance to the current query, or implement threshold-based filtering where only memories exceeding a minimum importance score are considered. The right approach depends on whether we prioritize surfacing the globally most important information or balancing importance with contextual relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_importance(memories: List[Memory],\n",
    "                        top_k: int = 3,\n",
    "                        min_importance: float = 0.0,\n",
    "                        weights: Optional[Dict[str, float]] = None) -> List[Memory]:\n",
    "    \"\"\"Select memories based on importance scores using top-k ranking.\n",
    "    \n",
    "    Args:\n",
    "        memories: List of all available memories\n",
    "        top_k: Number of memories to select (default: 3)\n",
    "        min_importance: Minimum importance threshold; memories below this are excluded (default: 0.0)\n",
    "        weights: Optional custom weights for importance calculation (default: None uses standard weights)\n",
    "        \n",
    "    Returns:\n",
    "        List of selected memories, sorted by importance (highest first)\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate importance score for each memory\n",
    "    scored_memories = []  # Store as tuples of (memory, score) for sorting\n",
    "    for mem in memories:\n",
    "        # Calculate score using either custom or default weights\n",
    "        score = mem.calculate_importance_score(weights=weights)\n",
    "        scored_memories.append((mem, score))\n",
    "    \n",
    "    # Step 2: Filter by minimum importance threshold - This removes low-value memories even if they would fit in top-k\n",
    "    filtered = [(mem, score) for mem, score in scored_memories if score >= min_importance]\n",
    "    \n",
    "    # Step 3: Sort by importance score in descending order (highest first)\n",
    "    filtered.sort(key=lambda x: x[1], reverse=True)  # The key function extracts the score (second element of tuple) for comparison\n",
    "    \n",
    "    # Step 4: Take only the top k memories\n",
    "    selected = [mem for mem, score in filtered[:top_k]]  # Extract just the memory objects (first element of tuple)\n",
    "    \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our importance-based selection function with our sample memories to see it in action. We will select the top 3 most important memories from our collection of 6, which should surface the memories with the strongest combination of signals across feedback, task success, business value, recency, and access frequency. Beyond just showing which memories were selected, we will also display the specific reasons why each memory was deemed important - this explainability is crucial for debugging selection behavior and building trust in production systems where stakeholders need to understand why certain information is being prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance-Based Memory Selection\n",
      "======================================================================\n",
      "\n",
      "Selected top 3 memories from 6 total:\n",
      "\n",
      "1. [Importance: 0.859]\n",
      "   User prefers eco-friendly packaging and sustainable products\n",
      "   Why important:\n",
      "     • Positive user feedback (+1.0)\n",
      "     • Explicitly saved by user\n",
      "     • Led to successful outcome\n",
      "     • High business value (0.8)\n",
      "     • Frequently accessed (5x)\n",
      "\n",
      "2. [Importance: 0.858]\n",
      "   Recommended cooling pad, user purchased it and left positive review\n",
      "   Why important:\n",
      "     • Positive user feedback (+1.0)\n",
      "     • Led to successful outcome\n",
      "     • High business value (0.7)\n",
      "\n",
      "3. [Importance: 0.787]\n",
      "   User's budget range is $800-$1200 for electronics\n",
      "   Why important:\n",
      "     • Led to successful outcome\n",
      "     • High business value (0.9)\n",
      "     • Frequently accessed (8x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test importance-based selection with our sample memories\n",
    "print(\"Importance-Based Memory Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select top 3 memories based on importance scores\n",
    "selected = select_by_importance(sample_memories, top_k=3)  # Using default weights and no minimum threshold\n",
    "\n",
    "print(f\"\\nSelected top 3 memories from {len(sample_memories)} total:\\n\")\n",
    "\n",
    "# Display each selected memory with its importance score and contributing factors\n",
    "for i, mem in enumerate(selected, 1):\n",
    "    # Recalculate score for display (already calculated during selection)\n",
    "    score = mem.calculate_importance_score()\n",
    "    # Show rank, score, and content\n",
    "    print(f\"{i}. [Importance: {score:.3f}]\")\n",
    "    print(f\"   {mem.content}\")\n",
    "    print(f\"   Why important:\")\n",
    "\n",
    "    # Build a list of reasons this memory scored highly - These are the signals that contributed to its high importance\n",
    "    reasons = []\n",
    "    # Check for positive user feedback\n",
    "    if mem.user_feedback_score > 0.5:\n",
    "        reasons.append(f\"Positive user feedback ({mem.user_feedback_score:+.1f})\")\n",
    "    # Check if user explicitly saved this memory\n",
    "    if mem.user_explicitly_saved:\n",
    "        reasons.append(\"Explicitly saved by user\")\n",
    "    # Check for task success\n",
    "    if mem.led_to_task_success:\n",
    "        reasons.append(\"Led to successful outcome\")\n",
    "    # Check for high business value\n",
    "    if mem.business_value > 0.6:\n",
    "        reasons.append(f\"High business value ({mem.business_value:.1f})\")\n",
    "    # Check for frequent access (indicates ongoing relevance)\n",
    "    if mem.access_count > 4:\n",
    "        reasons.append(f\"Frequently accessed ({mem.access_count}x)\")\n",
    "\n",
    "    # Display all contributing reasons\n",
    "    for reason in reasons:\n",
    "        print(f\"     • {reason}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance-based selection surfaces the most valuable memories:\n",
    "1. Implements top-k selection that ranks memories by composite importance scores and selects the highest-scoring subset.\n",
    "2. Applies optional minimum importance thresholds to exclude low-value memories even if they would fit in top-k.\n",
    "3. Demonstrates that memories with strong signals across multiple dimensions (user feedback, task success, business value) rise to the top.\n",
    "4. Provides explainability by showing which importance factors contributed to each memory's selection.\n",
    "\n",
    "This ensures agents prioritize information that has proven valuable through actual usage and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Balancing importance with contextual relevance\n",
    "\n",
    "Pure importance-based selection has a limitation: it may surface globally important memories that are irrelevant to the current query. A user preference for sustainable products is highly important overall, but if the current query asks about shipping times, that preference adds no value to the response. We need to balance importance with contextual relevance.\n",
    "\n",
    "The solution is hybrid selection that balances importance with semantic similarity to the current query. We calculate two scores for each memory: the importance score we have already implemented, and a relevance score based on how semantically similar the memory content is to the user's query. We then combine these scores using configurable weights, allowing us to tune whether we prioritize surfacing globally important information or contextually precise information. This is implemented through embedding-based similarity where we convert both the query and memory content into vector representations and calculate cosine similarity.\n",
    "\n",
    "The beauty of this approach is its flexibility. For a customer support agent where contextual precision matters greatly, we might weight relevance at 70% and importance at 30%. For a sales agent where certain user preferences should always be considered regardless of context, we might weight importance at 80% and relevance at 20%. The hybrid scoring ensures that memories must pass both bars - they need to be valuable and relevant - preventing the pitfalls of pure importance or pure similarity-based selection. Let's implement this sophisticated selection strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_importance_and_relevance(memories: List[Memory],\n",
    "                                       query: str,\n",
    "                                       embeddings: OpenAIEmbeddings,\n",
    "                                       top_k: int = 3,\n",
    "                                       importance_weight: float = 0.6,\n",
    "                                       relevance_weight: float = 0.4) -> List[Memory]:\n",
    "    \"\"\"Select memories balancing importance and contextual relevance.\n",
    "    \n",
    "    Args:\n",
    "        memories: List of all available memories\n",
    "        query: Current user query for relevance calculation\n",
    "        embeddings: Embedding model for semantic similarity\n",
    "        top_k: Number of memories to select\n",
    "        importance_weight: Weight for importance score (0-1), higher = prioritize important memories\n",
    "        relevance_weight: Weight for relevance score (0-1), higher = prioritize contextually relevant memories\n",
    "        \n",
    "    Returns:\n",
    "        List of selected memories balancing both factors\n",
    "    \"\"\"\n",
    "    # Step 1: Get embedding vector for the user's query\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    \n",
    "    # Step 2: Calculate both importance and relevance for each memory\n",
    "    scored_memories = []\n",
    "    \n",
    "    for mem in memories:\n",
    "        # Calculate importance score using our existing method\n",
    "        importance = mem.calculate_importance_score()  # This is the global value score independent of context\n",
    "        \n",
    "        # Calculate semantic relevance to current query\n",
    "        mem_embedding = embeddings.embed_query(mem.content)  # Convert memory content to vector representation\n",
    "        \n",
    "        # Calculate cosine similarity between query and memory vectors\n",
    "        similarity = np.dot(query_embedding, mem_embedding) / (\n",
    "            np.linalg.norm(query_embedding) * np.linalg.norm(mem_embedding)\n",
    "        )\n",
    "        relevance = (similarity + 1) / 2  # Normalize cosine similarity from [-1, 1] to [0, 1] range\n",
    "        \n",
    "        # Combine importance and relevance using weighted average - importance_weight + relevance_weight should sum to 1\n",
    "        combined_score = (importance_weight * importance + \n",
    "                         relevance_weight * relevance)\n",
    "\n",
    "        # Store all scores for sorting and analysis\n",
    "        scored_memories.append((mem, combined_score, importance, relevance))\n",
    "    \n",
    "    # Step 3: Sort by combined score (highest first)\n",
    "    scored_memories.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Step 4: Return top k memories with their detailed scores\n",
    "    return scored_memories[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation combines importance-based selection with semantic relevance through a hybrid scoring function that calculates both dimensions for each memory, applies configurable weights to balance global value against contextual fit, and returns memories ranked by their combined scores along with the breakdown showing how each dimension contributed. Let's demonstrate context-aware selection across three different query types: price-related queries surface the budget preference, sustainability queries surface the eco-friendly preference, and technical queries surface the cooling pad recommendation, proving that the same memory store produces different selections based on contextual relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Selection: Importance + Contextual Relevance\n",
      "======================================================================\n",
      "\n",
      "Query: 'I'm looking for a new laptop in my price range'\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 3 memories (60% importance, 40% relevance):\n",
      "\n",
      "1. [Combined: 0.869 | Importance: 0.859 | Relevance: 0.884]\n",
      "   User prefers eco-friendly packaging and sustainable products\n",
      "\n",
      "2. [Combined: 0.868 | Importance: 0.858 | Relevance: 0.883]\n",
      "   Recommended cooling pad, user purchased it and left positive review\n",
      "\n",
      "3. [Combined: 0.840 | Importance: 0.787 | Relevance: 0.919]\n",
      "   User's budget range is $800-$1200 for electronics\n",
      "\n",
      "\n",
      "Query: 'Tell me about eco-friendly product options'\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 3 memories (60% importance, 40% relevance):\n",
      "\n",
      "1. [Combined: 0.895 | Importance: 0.859 | Relevance: 0.949]\n",
      "   User prefers eco-friendly packaging and sustainable products\n",
      "\n",
      "2. [Combined: 0.865 | Importance: 0.858 | Relevance: 0.877]\n",
      "   Recommended cooling pad, user purchased it and left positive review\n",
      "\n",
      "3. [Combined: 0.826 | Importance: 0.787 | Relevance: 0.884]\n",
      "   User's budget range is $800-$1200 for electronics\n",
      "\n",
      "\n",
      "Query: 'What cooling solutions do you recommend?'\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 3 memories (60% importance, 40% relevance):\n",
      "\n",
      "1. [Combined: 0.877 | Importance: 0.858 | Relevance: 0.905]\n",
      "   Recommended cooling pad, user purchased it and left positive review\n",
      "\n",
      "2. [Combined: 0.867 | Importance: 0.859 | Relevance: 0.880]\n",
      "   User prefers eco-friendly packaging and sustainable products\n",
      "\n",
      "3. [Combined: 0.819 | Importance: 0.787 | Relevance: 0.867]\n",
      "   User's budget range is $800-$1200 for electronics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test hybrid selection with different query types - Each query should surface different memories based on contextual relevance\n",
    "test_queries = [\n",
    "    \"I'm looking for a new laptop in my price range\",      # Should surface budget preference\n",
    "    \"Tell me about eco-friendly product options\",           # Should surface sustainability preference\n",
    "    \"What cooling solutions do you recommend?\"              # Should surface cooling pad recommendation\n",
    "]\n",
    "\n",
    "print(\"Hybrid Selection: Importance + Contextual Relevance\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run selection for each query to demonstrate context-aware selection\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Select memories with 60% importance weight, 40% relevance weight\n",
    "    selected = select_by_importance_and_relevance(\n",
    "        sample_memories, \n",
    "        query, \n",
    "        embeddings,\n",
    "        top_k=3,  # Select top 3 memories\n",
    "        importance_weight=0.6,  # 60% weight on importance\n",
    "        relevance_weight=0.4  # 40% weight on relevance\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTop 3 memories (60% importance, 40% relevance):\\n\")\n",
    "\n",
    "    # Display each selected memory with score breakdown\n",
    "    for i, (mem, combined, importance, relevance) in enumerate(selected, 1):\n",
    "        print(f\"{i}. [Combined: {combined:.3f} | Importance: {importance:.3f} | Relevance: {relevance:.3f}]\")\n",
    "        print(f\"   {mem.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid selection balances global importance with contextual fit:\n",
    "1. Implements combined scoring that weights both importance and semantic relevance to current query, preventing irrelevant but important memories from dominating.\n",
    "2. Uses configurable weight parameters allowing tuning based on whether you prioritize surfacing important information or contextually precise information.\n",
    "3. Demonstrates how different queries select different memory subsets - budget preference surfaces for price-related queries, sustainability for eco-queries, cooling success for technical queries.\n",
    "4. Returns scoring breakdowns showing how importance and relevance each contributed to final selection, providing transparency and debuggability.\n",
    "\n",
    "This sophisticated approach ensures memories are both valuable and applicable to the current conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Token-constrained memory selection\n",
    "\n",
    "In production AI systems, one of the hardest constraints we face is the finite context window. While top-k selection gives us control over the number of memories, it does not account for the fact that different memories consume different amounts of tokens - a brief preference like \"User prefers dark mode\" might use 5 tokens, while a detailed product recommendation could use 30 tokens. If we select a fixed count of memories, we might wastefully use only 40% of our available context budget, or we might exceed it entirely and cause truncation errors. What we really need is to pack as many high-value memories as possible into our available token budget, maximizing the information density of our context.\n",
    "\n",
    "This is a classic optimization problem known as the knapsack problem: given items with values (importance scores) and weights (token counts), select the subset that maximizes total value while staying under a weight limit. While the optimal solution requires dynamic programming with O(n * budget) complexity, a greedy approximation works remarkably well in practice - sort memories by their combined score, then add them one by one until the budget is exhausted. This greedy approach has O(n log n) complexity and typically achieves near-optimal results because importance scores already capture value density, and we are selecting the highest-value items first.\n",
    "\n",
    "Token-constrained selection adapts our previous selection strategies to respect hard budget limits. If we are doing pure importance selection, we sort by importance and pack greedily. If we are doing hybrid importance-relevance selection, we use those combined scores for ranking. The result is a selection that makes optimal use of available context space, ensuring we do not waste tokens on padding while preventing overflow errors. Let's implement this crucial production feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Estimate token count for text using a rough word-based approximation.\n",
    "        \n",
    "    Args:\n",
    "        text: Text to estimate token count for\n",
    "        \n",
    "    Returns:\n",
    "        Estimated token count\n",
    "    \"\"\"\n",
    "    # Rough estimate based on empirical observation: English text averages ~0.75 tokens per word\n",
    "    # This varies by language and technical content but works well for estimation\n",
    "    words = len(text.split())\n",
    "    return int(words * 0.75)\n",
    "\n",
    "def select_with_token_budget(memories: List[Memory],\n",
    "                            token_budget: int,\n",
    "                            query: Optional[str] = None,\n",
    "                            embeddings: Optional[OpenAIEmbeddings] = None,\n",
    "                            importance_weight: float = 0.7,\n",
    "                            relevance_weight: float = 0.3) -> Dict:\n",
    "    \"\"\"\n",
    "    Select memories to maximize importance within a token budget constraint.\n",
    "        \n",
    "    Args:\n",
    "        memories: List of all available memories\n",
    "        token_budget: Maximum tokens to use for memory content\n",
    "        query: Optional query for hybrid selection (if None, uses pure importance)\n",
    "        embeddings: Embedding model required if query provided\n",
    "        importance_weight: Weight for importance in hybrid scoring\n",
    "        relevance_weight: Weight for relevance in hybrid scoring\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing:\n",
    "        - memories: Selected memory objects\n",
    "        - memory_count: Number of memories selected\n",
    "        - total_tokens: Actual tokens used\n",
    "        - budget_used_pct: Percentage of budget utilized\n",
    "        - avg_importance: Average importance of selected memories\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate scores for each memory - Choose scoring method based on whether query is provided\n",
    "    if query and embeddings:\n",
    "        # Use hybrid importance + relevance scoring\n",
    "        scored = select_by_importance_and_relevance(\n",
    "            memories, query, embeddings, \n",
    "            top_k=len(memories),  # Get all memories ranked, we will filter by budget\n",
    "            importance_weight=importance_weight,\n",
    "            relevance_weight=relevance_weight\n",
    "        )\n",
    "        # Extract (memory, combined_score) tuples from full results\n",
    "        scored_memories = [(mem, score) for mem, score, _, _ in scored]\n",
    "    else:\n",
    "        # Use pure importance scoring without contextual relevance\n",
    "        scored_memories = [(mem, mem.calculate_importance_score()) for mem in memories]\n",
    "        # Sort by importance score in descending order\n",
    "        scored_memories.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Step 2: Greedy selection to maximize value within budget - Add memories in order of score until budget is exhausted\n",
    "    selected = []\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for mem, score in scored_memories:\n",
    "        # Calculate tokens required for this memory\n",
    "        mem_tokens = estimate_tokens(mem.content)\n",
    "        \n",
    "        # Only add memory if it fits within remaining budget - This is the greedy decision: add if possible, skip otherwise\n",
    "        if total_tokens + mem_tokens <= token_budget:\n",
    "            selected.append((mem, score, mem_tokens))\n",
    "            total_tokens += mem_tokens\n",
    "        # Could continue to find smaller memories that fit, but greedy is often sufficient\n",
    "\n",
    "    # Step 3: Compile results with metadata for monitoring and debugging\n",
    "    return {\n",
    "        \"memories\": [mem for mem, _, _ in selected],  # Just the memory objects\n",
    "        \"memory_count\": len(selected),  # How many memories fit\n",
    "        \"total_tokens\": total_tokens,  # Actual tokens used\n",
    "        \"budget_used_pct\": (total_tokens / token_budget * 100) if token_budget > 0 else 0,  # Efficiency metric\n",
    "        \"avg_importance\": sum(score for _, score, _ in selected) / len(selected) if selected else 0  # Quality metric\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation provides token-aware memory selection through a greedy knapsack algorithm that estimates token consumption for each memory, ranks memories by importance or hybrid scores, and iteratively adds memories until the token budget is exhausted, returning both the selected memories and rich metadata about budget utilization and selection quality. Let's demonstrate adaptive behavior across three budget levels: tight budgets (30 tokens) select only 1-2 critical memories, moderate budgets (50 tokens) fit 2-3 memories, and generous budgets (100 tokens) accommodate 4+ memories, with each configuration maximizing value density within available space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-Constrained Memory Selection\n",
      "======================================================================\n",
      "\n",
      "Token Budget: 30 tokens\n",
      "----------------------------------------------------------------------\n",
      "Selected: 5 memories\n",
      "Used: 26/30 tokens (86.7%)\n",
      "Avg importance: 0.748\n",
      "\n",
      "Memories included:\n",
      "  1. [7 tokens] Recommended cooling pad, user purchased it and left positive...\n",
      "  2. [5 tokens] User prefers eco-friendly packaging and sustainable products...\n",
      "  3. [5 tokens] User's budget range is $800-$1200 for electronics...\n",
      "  4. [4 tokens] User mentioned they work from home...\n",
      "  5. [5 tokens] User asked about laptop specifications on 2024-01-15...\n",
      "\n",
      "\n",
      "Token Budget: 50 tokens\n",
      "----------------------------------------------------------------------\n",
      "Selected: 6 memories\n",
      "Used: 31/50 tokens (62.0%)\n",
      "Avg importance: 0.708\n",
      "\n",
      "Memories included:\n",
      "  1. [7 tokens] Recommended cooling pad, user purchased it and left positive...\n",
      "  2. [5 tokens] User prefers eco-friendly packaging and sustainable products...\n",
      "  3. [5 tokens] User's budget range is $800-$1200 for electronics...\n",
      "  4. [4 tokens] User mentioned they work from home...\n",
      "  5. [5 tokens] User asked about laptop specifications on 2024-01-15...\n",
      "  6. [5 tokens] Previous recommendation for expensive laptop was rejected...\n",
      "\n",
      "\n",
      "Token Budget: 100 tokens\n",
      "----------------------------------------------------------------------\n",
      "Selected: 6 memories\n",
      "Used: 31/100 tokens (31.0%)\n",
      "Avg importance: 0.708\n",
      "\n",
      "Memories included:\n",
      "  1. [7 tokens] Recommended cooling pad, user purchased it and left positive...\n",
      "  2. [5 tokens] User prefers eco-friendly packaging and sustainable products...\n",
      "  3. [5 tokens] User's budget range is $800-$1200 for electronics...\n",
      "  4. [4 tokens] User mentioned they work from home...\n",
      "  5. [5 tokens] User asked about laptop specifications on 2024-01-15...\n",
      "  6. [5 tokens] Previous recommendation for expensive laptop was rejected...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test token-constrained selection with varying budget levels\n",
    "print(\"Token-Constrained Memory Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test with tight, moderate, and generous budgets\n",
    "budgets = [30, 50, 100]\n",
    "query = \"I need laptop recommendations\"\n",
    "\n",
    "for budget in budgets:\n",
    "    # Run selection with current budget\n",
    "    result = select_with_token_budget(\n",
    "        sample_memories,\n",
    "        token_budget=budget,\n",
    "        query=query,  # Use hybrid scoring with query relevance\n",
    "        embeddings=embeddings\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nToken Budget: {budget} tokens\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Selected: {result['memory_count']} memories\")\n",
    "    print(f\"Used: {result['total_tokens']}/{budget} tokens ({result['budget_used_pct']:.1f}%)\")\n",
    "    print(f\"Avg importance: {result['avg_importance']:.3f}\")\n",
    "    print(f\"\\nMemories included:\")\n",
    "\n",
    "    # Show which memories fit in this budget\n",
    "    for i, mem in enumerate(result['memories'], 1):\n",
    "        tokens = estimate_tokens(mem.content)\n",
    "        # Truncate long content for display\n",
    "        print(f\"  {i}. [{tokens} tokens] {mem.content[:60]}...\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token-constrained selection optimizes context usage:\n",
    "1. Implements token estimation for memory content to calculate space requirements accurately.\n",
    "2. Uses greedy selection algorithm that adds highest-value memories first until budget is exhausted, maximizing importance within constraints.\n",
    "3. Tests multiple budget levels showing how memory selection adapts to available space - fewer memories at tight budgets, more at generous budgets.\n",
    "4. Reports budget utilization and average importance metrics, enabling monitoring of selection efficiency and quality.\n",
    "\n",
    "This ensures production agents make optimal use of limited context windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Production memory selection system\n",
    "\n",
    "Bringing together all the techniques we have explored, we can now build a production-ready memory selection system that combines importance scoring, contextual relevance, and token budget management. This system should provide a clean interface for agents, handle various memory types appropriately, track selection metadata for observability, and adapt to different use cases through configurable parameters.\n",
    "\n",
    "The production system integrates importance calculation, hybrid scoring, token budgeting, and selection logging into a cohesive architecture. This enables agents to seamlessly access the most valuable, relevant memories while respecting context constraints and providing transparency into selection decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemorySelector:\n",
    "    \"\"\"Production memory selection system with importance-based ranking.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embeddings: OpenAIEmbeddings,\n",
    "                 default_importance_weight: float = 0.6,\n",
    "                 default_relevance_weight: float = 0.4):\n",
    "        \"\"\"\n",
    "        Initialize memory selector with embedding model and default weights.\n",
    "        \n",
    "        Args:\n",
    "            embeddings: Embedding model for semantic similarity (required for hybrid selection)\n",
    "            default_importance_weight: Default weight for importance in hybrid scoring\n",
    "            default_relevance_weight: Default weight for relevance in hybrid scoring\n",
    "        \"\"\"\n",
    "        self.embeddings = embeddings\n",
    "        self.importance_weight = default_importance_weight\n",
    "        self.relevance_weight = default_relevance_weight\n",
    "    \n",
    "    def select(self,\n",
    "              memories: List[Memory],\n",
    "              query: Optional[str] = None,\n",
    "              token_budget: Optional[int] = None,\n",
    "              top_k: Optional[int] = None,\n",
    "              min_importance: float = 0.0,\n",
    "              memory_types: Optional[List[MemoryType]] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Select memories using appropriate strategy based on provided parameters.\n",
    "        \n",
    "        Strategy selection logic:\n",
    "        - If token_budget provided: Use token-constrained selection\n",
    "        - Elif top_k provided: Use top-k selection (hybrid if query, pure importance otherwise)\n",
    "        - Else: Return all memories passing filters\n",
    "        \n",
    "        Args:\n",
    "            memories: All available memories to select from\n",
    "            query: Optional query for hybrid relevance scoring\n",
    "            token_budget: Optional maximum tokens (triggers token-constrained selection)\n",
    "            top_k: Optional maximum count (triggers top-k selection)\n",
    "            min_importance: Minimum importance threshold (applied before selection)\n",
    "            memory_types: Optional list of types to filter to (e.g., [USER_PREFERENCE, TASK_OUTCOME])\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing:\n",
    "            - selected_memories: List of selected Memory objects\n",
    "            - count: Number of memories selected\n",
    "            - avg_importance: Average importance of selected memories\n",
    "            - metadata: Strategy-specific information (method, parameters, efficiency)\n",
    "            - total_available: How many memories were available after filtering\n",
    "        \"\"\"\n",
    "        # Step 1: Apply pre-selection filters\n",
    "        # Filter by memory type if specified - Allows selecting only preferences, only outcomes, etc.\n",
    "        if memory_types:\n",
    "            memories = [m for m in memories if m.memory_type in memory_types]\n",
    "        \n",
    "        # Filter by minimum importance threshold - Removes low-value memories before selection\n",
    "        memories = [m for m in memories \n",
    "                   if m.calculate_importance_score() >= min_importance]\n",
    "        \n",
    "        # Step 2: Select appropriate strategy based on constraints\n",
    "        if token_budget:\n",
    "            # Use token-constrained selection to maximize value within budget\n",
    "            result = select_with_token_budget(\n",
    "                memories,\n",
    "                token_budget=token_budget,\n",
    "                query=query,  # May be None (pure importance) or provided (hybrid)\n",
    "                embeddings=self.embeddings if query else None,\n",
    "                importance_weight=self.importance_weight,\n",
    "                relevance_weight=self.relevance_weight\n",
    "            )\n",
    "            selected_memories = result['memories']\n",
    "            # Build metadata with token budget information\n",
    "            metadata = {\n",
    "                'selection_method': 'token_budget',\n",
    "                'token_budget': token_budget,\n",
    "                'tokens_used': result['total_tokens'],\n",
    "                'budget_efficiency': result['budget_used_pct']\n",
    "            }\n",
    "        elif top_k:\n",
    "            # Use top-k selection\n",
    "            if query:\n",
    "                # Hybrid selection: balance importance and relevance\n",
    "                scored = select_by_importance_and_relevance(\n",
    "                    memories, query, self.embeddings, top_k=top_k,\n",
    "                    importance_weight=self.importance_weight,\n",
    "                    relevance_weight=self.relevance_weight\n",
    "                )\n",
    "                # Extract just the memory objects from scored results\n",
    "                selected_memories = [m for m, _, _, _ in scored]\n",
    "            else:\n",
    "                # Pure importance selection: no query context\n",
    "                selected_memories = select_by_importance(\n",
    "                    memories, top_k=top_k, min_importance=min_importance\n",
    "                )\n",
    "            # Build metadata indicating which variant was used\n",
    "            metadata = {\n",
    "                'selection_method': 'top_k_hybrid' if query else 'top_k_importance',\n",
    "                'top_k': top_k\n",
    "            }\n",
    "        else:\n",
    "            # Default: return all memories that passed filters - Useful when filters alone (type, min_importance) are sufficient\n",
    "            selected_memories = memories\n",
    "            metadata = {\n",
    "                'selection_method': 'filter_only'\n",
    "            }\n",
    "        \n",
    "        # Step 3: Update access tracking for selected memories - This is critical for importance scoring based on usage frequency\n",
    "        for mem in selected_memories:\n",
    "            mem.access_count += 1  # Increment usage counter\n",
    "            mem.last_accessed = datetime.now()  # Record access time\n",
    "        \n",
    "        # Step 4: Compile comprehensive results\n",
    "        return {\n",
    "            'selected_memories': selected_memories,\n",
    "            'count': len(selected_memories),\n",
    "            # Calculate average importance as quality metric\n",
    "            'avg_importance': sum(m.calculate_importance_score() for m in selected_memories) / len(selected_memories) if selected_memories else 0,\n",
    "            'metadata': metadata,  # Strategy-specific details\n",
    "            'total_available': len(memories)  # For monitoring filter effectiveness\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MemorySelector` class provides a unified production interface that integrates all selection strategies (pure importance, hybrid importance-relevance, token-constrained) into a single select method with automatic strategy dispatch based on provided parameters. The implementation applies pre-selection filters for memory type and minimum importance, intelligently chooses between token-budget, top-k, or filter-only strategies, automatically updates access tracking for selected memories to feed back into future importance calculations, and returns comprehensive results with strategy-specific metadata enabling monitoring and debugging. Let's demonstrate real-world usage patterns: tight-budget query-aware selection, type-filtered preference selection, and high-importance outcome selection with quality thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Memory Selection System\n",
      "======================================================================\n",
      "\n",
      "Scenario: Budget-constrained with query\n",
      "----------------------------------------------------------------------\n",
      "Method: token_budget\n",
      "Selected: 6 of 6 memories\n",
      "Avg importance: 0.628\n",
      "Tokens: 31/60\n",
      "\n",
      "Selected memories:\n",
      "  1. [Imp: 0.862] User prefers eco-friendly packaging and sustainable products...\n",
      "  2. [Imp: 0.864] Recommended cooling pad, user purchased it and left positive...\n",
      "  3. [Imp: 0.789] User's budget range is $800-$1200 for electronics...\n",
      "  4. [Imp: 0.519] User mentioned they work from home...\n",
      "  5. [Imp: 0.405] User asked about laptop specifications on 2024-01-15...\n",
      "  6. [Imp: 0.328] Previous recommendation for expensive laptop was rejected...\n",
      "\n",
      "\n",
      "Scenario: Top-3 preferences only\n",
      "----------------------------------------------------------------------\n",
      "Method: top_k_importance\n",
      "Selected: 2 of 2 memories\n",
      "Avg importance: 0.828\n",
      "\n",
      "Selected memories:\n",
      "  1. [Imp: 0.864] User prefers eco-friendly packaging and sustainable products...\n",
      "  2. [Imp: 0.791] User's budget range is $800-$1200 for electronics...\n",
      "\n",
      "\n",
      "Scenario: High-importance task outcomes\n",
      "----------------------------------------------------------------------\n",
      "Method: top_k_importance\n",
      "Selected: 1 of 1 memories\n",
      "Avg importance: 0.868\n",
      "\n",
      "Selected memories:\n",
      "  1. [Imp: 0.868] Recommended cooling pad, user purchased it and left positive...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create selector and test with various scenarios\n",
    "selector = MemorySelector(embeddings)\n",
    "\n",
    "print(\"Production Memory Selection System\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test various production scenarios\n",
    "scenarios = [\n",
    "    {\n",
    "        'name': 'Budget-constrained with query',\n",
    "        'query': \"Looking for laptop within budget\",\n",
    "        'token_budget': 60,  # Tight budget requiring optimization\n",
    "    },\n",
    "    {\n",
    "        'name': 'Top-3 preferences only',\n",
    "        'top_k': 3,\n",
    "        'memory_types': [MemoryType.USER_PREFERENCE]  # Filter to just preferences\n",
    "    },\n",
    "    {\n",
    "        'name': 'High-importance task outcomes',\n",
    "        'top_k': 2,\n",
    "        'min_importance': 0.5,  # Only high-value memories\n",
    "        'memory_types': [MemoryType.TASK_OUTCOME]  # Filter to task outcomes\n",
    "    },\n",
    "]\n",
    "\n",
    "# Run each scenario and display results\n",
    "for scenario in scenarios:\n",
    "    # Extract scenario name separately (not a select() parameter)\n",
    "    name = scenario.pop('name')\n",
    "    # Call unified select interface with scenario parameters\n",
    "    result = selector.select(sample_memories, **scenario)\n",
    "    \n",
    "    print(f\"\\nScenario: {name}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Method: {result['metadata']['selection_method']}\")\n",
    "    print(f\"Selected: {result['count']} of {result['total_available']} memories\")\n",
    "    print(f\"Avg importance: {result['avg_importance']:.3f}\")\n",
    "\n",
    "    # Show token usage if applicable\n",
    "    if 'token_budget' in result['metadata']:\n",
    "        print(f\"Tokens: {result['metadata']['tokens_used']}/{result['metadata']['token_budget']}\")\n",
    "\n",
    "    # Display selected memories\n",
    "    print(f\"\\nSelected memories:\")\n",
    "    for i, mem in enumerate(result['selected_memories'], 1):\n",
    "        imp = mem.calculate_importance_score()\n",
    "        print(f\"  {i}. [Imp: {imp:.3f}] {mem.content[:60]}...\")  # Truncate long content for display\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The production system provides comprehensive memory selection capabilities:\n",
    "1. Implements a unified interface supporting multiple selection strategies (token budget, top-k, filtering) through a single clean API.\n",
    "2. Handles optional query-based relevance scoring, gracefully falling back to importance-only when no query is provided.\n",
    "3. Supports memory type filtering and importance thresholds, enabling fine-grained control over what memories are considered.\n",
    "4. Tracks access patterns by incrementing counts and updating timestamps, enabling future importance calculations to consider usage frequency.\n",
    "5. Returns rich metadata about selection method, efficiency metrics, and aggregate statistics for monitoring and debugging.\n",
    "\n",
    "This architecture supports production agent systems with sophisticated memory management requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
